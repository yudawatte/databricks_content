{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22a79e9a-1cbc-4efc-a636-493ee68b2f21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"env_stage\", \"dev\", [\"dev\", \"prod\"], \"Pipeline stage\")\n",
    "\n",
    "dbutils.widgets.dropdown(\"exclude_pms\", \"False\", [\"True\", \"False\"], \"Exclude PMS\")\n",
    "\n",
    "dbutils.widgets.dropdown(\"target_type\", \"REVENUE\", [\"REVENUE\", \"ROOMS\"], \"Target Type\")\n",
    "\n",
    "dbutils.widgets.text(\"selected_hotels\", \"\", \"Hotels\")\n",
    "\n",
    "dbutils.widgets.text(\"lag_numbers\",\"1,7,14,28\", \"Lag Numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77630b36-91bb-471a-bc79-349334ed2bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3f7d67a-235a-4d69-9826-958f1707dbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b439e30-ac3d-4c13-9d1a-215c26e29092",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from typing import List\n",
    "import holidays\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from sys import version_info\n",
    "import cloudpickle\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "import datetime\n",
    "import logging\n",
    "import shutil\n",
    "import mlflow\n",
    "from mlflow import MlflowException\n",
    "import mlflow.pyfunc\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9eba875-3985-4380-bc07-238606eebd01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ed9188e-ad82-4379-9c9a-6de454ca85f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ENV = getArgument(\"env_stage\")\n",
    "\n",
    "REPOPATH = \"/Workspace/Repos/manik@surge.global/phg-data-mlsys/src\"\n",
    "cluster_name = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\") \n",
    "\n",
    "if (ENV == \"dev\") and (\"dev\" in cluster_name):\n",
    "    print(f\"Loading phgml package from repo {REPOPATH}\")\n",
    "    sys.path.append(os.path.abspath(REPOPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e42dbdc-c2e0-48ec-b93f-31421e251186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phgml.models.xgboost_model import XGBMultiStepPredictor\n",
    "from phgml.models.autogluon_model import AutoGluonModel, AGMlflowModel\n",
    "from phgml.models.lightgbm_model import LightGBMModel, LGBMMlflowModel\n",
    "from phgml.data.processing import get_lags\n",
    "from phgml.data.processing_distr import (\n",
    "    calc_date_features,\n",
    "    add_date_features,\n",
    "    preprocess_data,\n",
    "    filter_test_partition,\n",
    "    aggregate_target,\n",
    "    create_rows,\n",
    "    compile_test_table,\n",
    "    compile_hotel_tables,\n",
    "    remove_padded_cols,\n",
    "    filter_hotels\n",
    ")\n",
    "from phgml.reporting.output_metrics import *\n",
    "from phgml.reporting.report_results import get_output_df, correct_prediction_list\n",
    "from phgml.data.data_types import inference_output_schema\n",
    "from phgml.reporting.logging import get_logging_path, get_logging_filename, get_dbx_logger\n",
    "from phgml.data.config import EnvironmentConfig,ForecastingHotelConfigProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a778bf-a1f1-4777-b9f6-b7dff05b4a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def str_to_lst(value):\n",
    "    if value == \"\":\n",
    "        return []\n",
    "    elif \",\" in value:\n",
    "        hotels = value.split(\",\")\n",
    "        return hotels\n",
    "\n",
    "    return [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30d6cece-c93e-4e60-b79b-09be5d6929e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Disable adaptive query optimization\n",
    "# Adaptive query optimization groups together smaller tasks into a larger tasks.\n",
    "# This may result in limited parallelism if the parallel inference tasks are deemed to be too small by the query optimizer\n",
    "# We are diableing AQE here to circumevent this limitation on parallelism\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc088ca8-d19e-425b-b97b-9f436dc07dee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hotel_ids = spark.sql(\n",
    "    \"select distinct HotelID,HotelName from phg_data.consumption_deaggrecords\"\n",
    ").toPandas()\n",
    "hotel_ids = hotel_ids.sort_values(\"HotelID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e174bfc-728b-4416-8d02-85f995ce08b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def str_to_bool(value):\n",
    "    FALSE_VALUES = [\"false\", \"no\", \"0\"]\n",
    "    TRUE_VALUES = [\"true\", \"yes\", \"1\"]\n",
    "    lvalue = str(value).lower()\n",
    "    if lvalue in (FALSE_VALUES):\n",
    "        return False\n",
    "    if lvalue in (TRUE_VALUES):\n",
    "        return True\n",
    "    raise Exception(\n",
    "        \"String value should be one of {}, but got '{}'.\".format(\n",
    "            FALSE_VALUES + TRUE_VALUES, value\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68aacb4a-7087-4303-a629-8d3ad45cd658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# As a workaround for the bug PHG-2157\n",
    "PARTITION_DATE = spark.sql(\n",
    "    \"select max(confirmationDate) from phg_data.consumption_deaggrecords\"\n",
    ").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60fa1a13-7087-494f-8edd-901faf8cab8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# log_root = \"/dbfs/mnt/extractionlogs/synxis\"\n",
    "# processing_timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "479425c3-99e8-4190-80f0-9c8d7663972d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "REVENUE_COL = \"_reservationRevenuePerRoomUSD\"\n",
    "ROOMS_COL = \"_rooms\"\n",
    "PIPELINE = \"INFERENCE\"\n",
    "\n",
    "WITHOUT_PMS = str_to_bool(getArgument(\"exclude_pms\"))\n",
    "TARGET_TYPE = getArgument(\"target_type\")\n",
    "selected_hotels = str_to_lst(getArgument(\"selected_hotels\"))\n",
    "LAG_NUMBERS = list(map(int,str_to_lst(getArgument('lag_numbers'))))\n",
    "\n",
    "### The start of the model data\n",
    "MODEL_START_DATE = pd.to_datetime(\"2018-10-01\")\n",
    "\n",
    "COVID_START_DATE = pd.to_datetime(\"2020-03-01\")\n",
    "COVID_END_DATE = pd.to_datetime(\"2021-08-01\")\n",
    "\n",
    "CALC_UNCERTAINTY = False\n",
    "# MODEL_TYPE = \"XGB\"  # Use \"AG\" to try out the auto gloun approach\n",
    "MODEL_TYPE = \"AG\"\n",
    "\n",
    "LEAD_WINDOW = 60\n",
    "\n",
    "ML_EXPERIMENT_ID = 1079527465953184\n",
    "\n",
    "if MODEL_TYPE == \"XGB\":\n",
    "    RUN_ID = \"92907cac187f4c8cadb63ff60a05d72e\"  # XGB Run\n",
    "elif CALC_UNCERTAINTY and (MODEL_TYPE == \"AG\"):\n",
    "    RUN_ID = \"9549361574484dc58fcf1b7d130541a0\"\n",
    "else:\n",
    "    RUN_ID = \"19dee6420aed45f29e956016c5ea6e8a\"\n",
    "\n",
    "\n",
    "lead_window_start_days = 14\n",
    "lead_window_end_days = 60\n",
    "prediction_horizon = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b48239-d4d1-4799-b731-f311f8fb4ac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env_config = EnvironmentConfig(env=ENV, target=TARGET_TYPE, spark=spark)\n",
    "forecasting_config_provider = ForecastingHotelConfigProvider(spark=spark,env=ENV)\n",
    "target_column = env_config.target_column\n",
    "schema = inference_output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df829849-5e7f-4cad-81a8-f548b31ca727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_inference_length = spark.sql(f'select max(inference_prediction_length) from {forecasting_config_provider.config_table_name}').collect()[0][0]\n",
    "TEST_PARTIITON_END = PARTITION_DATE + pd.Timedelta(max_inference_length, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7e63ff0-6936-4674-90a1-8bfb2d997a44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger = get_dbx_logger(pipeline=PIPELINE,\n",
    "                        task_type=TARGET_TYPE,\n",
    "                        exclude_pms=WITHOUT_PMS)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ce80d34-c939-4522-996c-fcba42e9e397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Executing pipeline stage: {ENV}\")\n",
    "print(f\"Processing data for target type: {TARGET_TYPE} : {target_column}\")\n",
    "print(f\"Intermediate inference results table name: {env_config.inference_intermediate_table }\")\n",
    "print(f\"Writing inference results to table: {env_config.inference_output_table } with blob {env_config.inference_output_table_blob}\")\n",
    "print(f\"Excluding PMS data? {WITHOUT_PMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "761ed05d-ebc3-4ead-933f-956c554272e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Executing pipeline stage: {ENV}\")\n",
    "logger.info(f\"Processing data for target type: {TARGET_TYPE} : {target_column}\")\n",
    "logger.info(f\"Intermediate inference results table name: {env_config.inference_intermediate_table }\")\n",
    "logger.info(f\"Writing inference results to table: {env_config.inference_output_table } with blob {env_config.inference_output_table_blob}\")\n",
    "logger.info(f\"Excluding PMS data? {WITHOUT_PMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9411bf05-eeb3-4fea-a08e-109be8b8c228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Selecting hotels.\")\n",
    "\n",
    "hotel_details = spark.sql(\n",
    "    \"select HotelID,HotelName,PMSStartDate from phg_data.dim_hotels_\"\n",
    ").toPandas()\n",
    "\n",
    "#Filter hotels \n",
    "correct_hotel_ids = filter_hotels(hotel_details,selected_hotels,WITHOUT_PMS,forecasting_config_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e720a5d-5556-40d0-bc55-61ab74c3d300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"HotelID\",\n",
    "    \"_StayDates\",\n",
    "    \"confirmationDate\",\n",
    "    \"departureDate\",\n",
    "    \"channel\",\n",
    "    \"status\",\n",
    "    REVENUE_COL,\n",
    "    ROOMS_COL,\n",
    "]\n",
    "dfsp = spark.sql(\n",
    "    f\"select {','.join(columns)} from phg_data.consumption_deaggrecords where status='Confirmed'\"\n",
    ")\n",
    "\n",
    "if correct_hotel_ids:\n",
    "    print(f\"Filtering data for the selected hotels: {correct_hotel_ids}\")\n",
    "    dfsp = dfsp.filter(dfsp.HotelID.isin(correct_hotel_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e6abcf6-2962-472f-8a3b-bc6361d41adc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def debug_prediction(df, target_type, ml_experiment_id, run_id, exclude_pms, calc_uncertainty,hotel_config_provider,model_cache_dir):\n",
    "    fn = prediction_wrapper(target_type, ml_experiment_id, run_id, exclude_pms, calc_uncertainty,hotel_config_provider,model_cache_dir)\n",
    "    \n",
    "    return fn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba91d6fd-fc7f-48af-84c5-1956c9734960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pyfunc_load_model_retry(model_uri, max_tries):\n",
    "    '''Retry mechanism for loading models from mlflow model registry to \n",
    "    handle the model loading error\n",
    "    '''\n",
    "    loop_len = max_tries+1\n",
    "    for i in range(loop_len):\n",
    "            try:\n",
    "                return mlflow.pyfunc.load_model(model_uri)\n",
    "            except Exception as e:\n",
    "                if i+1==loop_len:\n",
    "                    raise e\n",
    "                else:\n",
    "                    print(e)\n",
    "                    print(f'Retrying: attempt {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cefa6b13-e0b3-404b-847d-1cce515e4516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prediction_wrapper(\n",
    "    target_type, ml_experiment_id, run_id, exclude_pms, calc_uncertainty,hotel_config_provider,model_cache_dir\n",
    "):\n",
    "    def predict_distributed(data):\n",
    "        static_cols_ = ['year', 'quarter_of_year', 'month_of_year', 'week_of_year',\n",
    "                         'day_of_year', 'month_of_quarter', 'week_of_quarter', 'day_of_quarter',\n",
    "                           'week_of_month', 'day_of_month', 'holiday',\n",
    "                             'day_of_week_0', 'day_of_week_1', 'day_of_week_2', \n",
    "                             'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6']\n",
    "\n",
    "        logger = get_dbx_logger(\"PHGML\")\n",
    "        \n",
    "        max_lead_window = 100\n",
    "        \n",
    "        hotel_id = data[\"HotelID\"].iloc[0]\n",
    "        hotel_config = hotel_config_provider.get_config(hotel_id)\n",
    "        model_type = hotel_config.model_name\n",
    "\n",
    "        print(f\"Processing Hotel {hotel_id}\")\n",
    "        \n",
    "        if target_type == \"REVENUE\":\n",
    "            col_prefix = \"RV\"\n",
    "        elif target_type == \"ROOMS\":\n",
    "            col_prefix = \"RM\"\n",
    "        \n",
    "        data = remove_padded_cols(data,hotel_config.lead_window,max_lead_window,col_prefix)\n",
    "        \n",
    "        model_version = 1\n",
    "        model_stage = \"Staging\"\n",
    "        model_name = None\n",
    "\n",
    "        try:\n",
    "\n",
    "            if model_type == \"LIGHTGBM\":\n",
    "                model_obj = LightGBMModel(prediction_horizon=hotel_config.inference_length,\n",
    "                                          hotel_id=hotel_id,\n",
    "                                          target_type=target_type,\n",
    "                                          exclude_pms=exclude_pms,\n",
    "                                          cd_axis_max_lags=99, \n",
    "                                          static_cols =static_cols_)\n",
    "                model_obj.set_latest_model_version(model_stage = 'Production')\n",
    "\n",
    "                loaded_model = pyfunc_load_model_retry(model_obj.get_model_uri(), 6)\n",
    "                    \n",
    "            elif model_type == \"AUTOGLUON\":\n",
    "\n",
    "                model_obj = AutoGluonModel(\n",
    "                    prediction_horizon=hotel_config.inference_length,\n",
    "                    calc_uncertainty=calc_uncertainty,\n",
    "                    mlflow_run_id=run_id,\n",
    "                    hotel_id=hotel_id,\n",
    "                    target_type=target_type,\n",
    "                    exclude_pms=exclude_pms,\n",
    "                )\n",
    "\n",
    "                model_obj.set_latest_model_version()\n",
    "            \n",
    "                pms = \"PMS\"\n",
    "                if exclude_pms:\n",
    "                    pms = \"NOPMS\"\n",
    "\n",
    "    #             dbfs_dir = f\"/dbfs/mnt/models/forecasting/individual_hotels/{hotel_id}_{target_type}_{pms}/\"\n",
    "                dbfs_dir = f\"{model_cache_dir}{hotel_id}_{target_type}_{pms}\" #f\"/dbfs/mnt/models/forecasting/dev_individual_hotels/{hotel_id}_{target_type}_{pms}/\"\n",
    "                local_dir = model_obj.local_root\n",
    "\n",
    "                if os.path.exists(local_dir):\n",
    "                    shutil.rmtree(local_dir)\n",
    "\n",
    "                # Copy cached model from blob storage to local dir\n",
    "                \n",
    "                shutil.copytree(dbfs_dir, local_dir)\n",
    "\n",
    "                # load model\n",
    "                loaded_model = load_pkl.load(path=model_obj.local_path)\n",
    "                loaded_model.prediction_horizon = model_obj.prediction_horizon\n",
    "\n",
    "            model_version = int(model_obj.version)\n",
    "            model_name = [\n",
    "                model_obj.get_model_name()\n",
    "                for step in range(1, hotel_config.inference_length + 1)\n",
    "            ]\n",
    "            model_metadata = model_obj.get_remote_model_metadata()\n",
    "            logger.info(\"Using model version {model_version}\")\n",
    "\n",
    "            logger.info(f\"Inference length of model: {model_metadata.get('inference_length','NOT_FOUND')}\")\n",
    "            logger.info(f\"Last trained date: {model_metadata.get('last_trained_date','NOT_FOUND')}\")\n",
    "\n",
    "           \n",
    "\n",
    "            y_pred_raw, y_test, y_upper_raw, y_lower_raw = loaded_model.predict(data)\n",
    "            y_pred, y_upper, y_lower = correct_prediction_list(\n",
    "                y_pred_raw, y_test, y_upper_raw, y_lower_raw\n",
    "            )\n",
    "\n",
    "            data[\"status\"] = \"complete\"\n",
    "            data[\"message\"] = f\"Successfully processed {hotel_id}\"\n",
    "\n",
    "            output_df = get_output_df(\n",
    "                y_pred=y_pred,\n",
    "                y_true=y_test,\n",
    "                run_id=run_id,\n",
    "                hotel_id=hotel_id,\n",
    "                data=data,\n",
    "                model_name=model_name,\n",
    "                model_version=model_version,\n",
    "                pms_sync_off=exclude_pms,\n",
    "                prediction_horizon=hotel_config.inference_length,\n",
    "                y_upper=y_upper,\n",
    "                y_lower=y_lower,\n",
    "                y_med_raw=y_pred_raw,\n",
    "                y_upper_raw=y_upper_raw,\n",
    "                y_lower_raw=y_lower_raw,\n",
    "            )\n",
    "\n",
    "            output_df[\"status\"] = \"complete\"\n",
    "            output_df[\"message\"] = f\"Successfully processed {hotel_id}\"\n",
    "\n",
    "        except MlflowException as e:\n",
    "            if \"RESOURCE_DOES_NOT_EXIST\" in e.message:\n",
    "                if model_type == \"XGB\":\n",
    "                    print(\n",
    "                        f\"Model {model.get_model_name()} was not  found in the model registry. Skipping this model...\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Model {model_obj.get_model_name()} was not  found in the model registry. Skipping this model...\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\"An MLFlowException occured\")\n",
    "                print(e)\n",
    "\n",
    "            empty = pd.DataFrame(\n",
    "                {\n",
    "                    \"HotelID\": [hotel_id],\n",
    "                    \"run_id\": [run_id],\n",
    "                    \"stay_date\": [pd.Timestamp(\"1900-01-01\")],\n",
    "                    \"booking_date\": [pd.Timestamp(\"1900-01-01\")],\n",
    "                    \"model_version\": [0],\n",
    "                    \"timestamp\": [pd.Timestamp(\"1900-01-01\")],\n",
    "                    \"pms_sync_off\": [exclude_pms],\n",
    "                    \"day_index\": [0],\n",
    "                    \"y_med\": [0],\n",
    "                    \"model_name\": [\"\"],\n",
    "                    \"y_upper\": [0],\n",
    "                    \"y_lower\": [0],\n",
    "                    \"y_med_raw\": [0],\n",
    "                    \"y_upper_raw\": [0],\n",
    "                    \"y_lower_raw\": [0],\n",
    "                    \"status\": \"incomplete\",\n",
    "                    \"message\": e.message,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            return empty\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Hotel {hotel_id} encountered an error \")\n",
    "            raise e\n",
    "        finally:\n",
    "            if model_type == \"AUTOGLUON\":\n",
    "                model_obj.clean()\n",
    "\n",
    "        return output_df\n",
    "\n",
    "    return predict_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd3221c2-7b20-4ea2-83ec-64fdb8162282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Preprocessing data\")\n",
    "df = preprocess_data(\n",
    "    dfsp,\n",
    "    WITHOUT_PMS,\n",
    "    REVENUE_COL,\n",
    "    ROOMS_COL,\n",
    "    MODEL_START_DATE,\n",
    "    COVID_START_DATE,\n",
    "    COVID_END_DATE,\n",
    ")\n",
    "\n",
    "logger.info(\"Calculating date features\")\n",
    "dates = calc_date_features(df)\n",
    "\n",
    "logger.info(\"Calculating lag features\")\n",
    "df_lags = get_lags(df.toPandas(),lag_numbers=LAG_NUMBERS, target_col=target_column)\n",
    "\n",
    "\n",
    "logger.info(\"Filtering test partition\")\n",
    "df = filter_test_partition(\n",
    "    df=df,\n",
    "    partition_start=PARTITION_DATE,\n",
    "    partition_end=TEST_PARTIITON_END,\n",
    "    revenue_col=REVENUE_COL,\n",
    "    rooms_col=ROOMS_COL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "526f36b5-fa52-4735-991b-5e2b18a4f8b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5aa3bc-3db2-4aa9-a6f7-6fa85afa7439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Compiling test data set\")\n",
    "df = compile_hotel_tables(\n",
    "    df, df_lags, dates,target_column=target_column,config_provider=forecasting_config_provider,compile_fn=compile_test_table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e5b30ac-2da4-43ec-b4ea-5ad8b16a4b5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# output = debug_prediction(df,MODEL_TYPE, TARGET_TYPE, ML_EXPERIMENT_ID, RUN_ID, WITHOUT_PMS, CALC_UNCERTAINTY,forecasting_config_provider,model_cache_dir=env_config.model_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8b032b5-9636-456d-9f00-836bfe551a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convere the data frame to Spark data frame and add status column for reporting purposes\n",
    "df = spark.createDataFrame(df)\n",
    "df = df.withColumn(\"status\", lit(\"incomplete\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddbb0d54-6277-4f50-9ac8-eee6c921252a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group the data by hotel id and execute the inferences in parallel\n",
    "logger.info(\"Starting parallell processing\")\n",
    "output_df = df.groupby(\"HotelID\").applyInPandas(\n",
    "    prediction_wrapper(\n",
    "        TARGET_TYPE, ML_EXPERIMENT_ID, RUN_ID, WITHOUT_PMS, CALC_UNCERTAINTY,forecasting_config_provider,model_cache_dir=env_config.model_cache_dir\n",
    "    ),\n",
    "    schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a058349d-9645-494c-a4d5-65ca6af3b40a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Drop intermediate results table if it exists\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {env_config.inference_intermediate_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41ef3fb5-902a-4c10-a7aa-b558dce1a7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Writing inference results to temporary table {env_config.inference_intermediate_table}\"\n",
    ")\n",
    "(\n",
    "    output_df.write.mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(env_config.inference_intermediate_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e821f6f8-278b-4e04-8fea-0e3c340b1932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "meta_columns = [\"HotelID\", \"run_id\", \"timestamp\", \"pms_sync_off\", \"status\", \"message\"]\n",
    "results_table = spark.sql(f\"select * from {env_config.inference_intermediate_table}\")\n",
    "output_meta = results_table.select(meta_columns).toPandas()\n",
    "\n",
    "num_completed = output_meta[output_meta[\"status\"] == \"complete\"][\"HotelID\"].nunique()\n",
    "total = output_meta[\"HotelID\"].nunique()\n",
    "logger.info(f\"{num_completed} out of {total} hotels processed succussfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ae85d72-41cf-4aaa-82dc-3617d8ed2301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "incomplete = output_meta[~(output_meta[\"status\"] == \"complete\")]\n",
    "\n",
    "for row in incomplete.itertuples():\n",
    "    logger.error(\n",
    "        f\"Error encountered when processing hotel {row.HotelID}: {row.message}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aedfa42c-c103-4287-b19d-e1e6c6d05045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df = results_table.filter(results_table.status == \"complete\").drop(\n",
    "    \"status\", \"message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf6c0bec-f8eb-433c-9754-48c566722cdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Writing completed results to table\")\n",
    "file_format = \"delta\"\n",
    "\n",
    "\n",
    "(\n",
    "    output_df.write.format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .partitionBy(\"HotelID\")\n",
    "    .option(\"path\", env_config.inference_output_table_blob)\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(env_config.inference_output_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5cf985a-bd5e-4501-ad60-ff9446dde261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "elapsed_time = time.perf_counter() - start_time\n",
    "logger.info(f\"Time elapsed {elapsed_time}\")\n",
    "logger.info(f\"Time elapsed in minutes {elapsed_time/60}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "forecast-inference-distributed-OLD",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}