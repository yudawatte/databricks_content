{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67f000b4-ab8d-420d-89b7-42dbd4fca1a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.dropdown(\"env_stage\", \"dev\", [\"dev\", \"prod\"], \"Pipeline stage\")\n",
    "dbutils.widgets.dropdown(\"exclude_pms\", \"False\", [\"True\", \"False\"], \"Exclude PMS\")\n",
    "dbutils.widgets.dropdown(\"target_type\", \"REVENUE\", [\"REVENUE\", \"ROOMS\"], \"Target Type\")\n",
    "dbutils.widgets.dropdown(\"is_usd_currency\", \"True\", [\"True\", \"False\"], \"Use USD currency\")\n",
    "dbutils.widgets.text(\"lag_numbers\",\"1,7,14,28\", \"Lag Numbers\")\n",
    "dbutils.widgets.text(\"model_tags\",\"\", \"Model Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b80ad4c-b8d5-4587-ad4d-83d9fee9a50d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Requirement already satisfied: mlflow==2.2.2 in /databricks/python3/lib/python3.8/site-packages (2.2.2)\n",
       "Requirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.6.2)\n",
       "Requirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.32.3)\n",
       "Requirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.3)\n",
       "Requirement already satisfied: markdown&lt;4,&gt;=3.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.7)\n",
       "Requirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.2.1)\n",
       "Requirement already satisfied: scikit-learn&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.0.2)\n",
       "Requirement already satisfied: shap&lt;1,&gt;=0.40 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.44.1)\n",
       "Requirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2020.5)\n",
       "Requirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.0.2)\n",
       "Requirement already satisfied: docker&lt;7,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.1.3)\n",
       "Requirement already satisfied: pandas&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.4.4)\n",
       "Requirement already satisfied: querystring-parser&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.2.4)\n",
       "Requirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.22.4)\n",
       "Requirement already satisfied: importlib-metadata!=4.7.0,&lt;7,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.11.0)\n",
       "Requirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.17.2)\n",
       "Requirement already satisfied: pyarrow&lt;12,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (4.0.0)\n",
       "Requirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.3.3)\n",
       "Requirement already satisfied: packaging&lt;24 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (23.2)\n",
       "Requirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.18.0)\n",
       "Requirement already satisfied: alembic&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.13.3)\n",
       "Requirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.5.1)\n",
       "Requirement already satisfied: matplotlib&lt;4 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.4.2)\n",
       "Requirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (20.1.0)\n",
       "Requirement already satisfied: Jinja2&lt;4,&gt;=2.11 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.1.4)\n",
       "Requirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.1.43)\n",
       "Requirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (8.1.7)\n",
       "Requirement already satisfied: sqlalchemy&lt;3,&gt;=1.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.0.35)\n",
       "Requirement already satisfied: importlib-resources in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (6.4.5)\n",
       "Requirement already satisfied: typing-extensions&gt;=4 in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (4.12.2)\n",
       "Requirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (1.3.5)\n",
       "Requirement already satisfied: oauthlib&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (3.2.2)\n",
       "Requirement already satisfied: pyjwt&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (2.9.0)\n",
       "Requirement already satisfied: urllib3&lt;3,&gt;=1.26.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (1.26.15)\n",
       "Requirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (0.9.0)\n",
       "Requirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (1.15.0)\n",
       "Requirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;7,&gt;=4.0.0-&gt;mlflow==2.2.2) (1.8.0)\n",
       "Requirement already satisfied: blinker&gt;=1.6.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (1.8.2)\n",
       "Requirement already satisfied: Werkzeug&gt;=2.3.7 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (3.0.4)\n",
       "Requirement already satisfied: itsdangerous&gt;=2.1.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (2.2.0)\n",
       "Requirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow==2.2.2) (4.0.11)\n",
       "Requirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow==2.2.2) (5.0.1)\n",
       "Requirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow==2.2.2) (52.0.0)\n",
       "Requirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;7,&gt;=3.7.0-&gt;mlflow==2.2.2) (3.20.2)\n",
       "Requirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&lt;4,&gt;=2.11-&gt;mlflow==2.2.2) (2.1.5)\n",
       "Requirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (0.10.0)\n",
       "Requirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (8.2.0)\n",
       "Requirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (2.4.7)\n",
       "Requirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (1.3.1)\n",
       "Requirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (2.8.1)\n",
       "Requirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (2020.12.5)\n",
       "Requirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (2.10)\n",
       "Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (3.3.2)\n",
       "Requirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow==2.2.2) (1.0.1)\n",
       "Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow==2.2.2) (2.1.0)\n",
       "Requirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.58.1)\n",
       "Requirement already satisfied: tqdm&gt;=4.27.0 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (4.66.5)\n",
       "Requirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.0.7)\n",
       "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.8/site-packages (from sqlalchemy&lt;3,&gt;=1.4.0-&gt;mlflow==2.2.2) (3.1.1)\n",
       "Requirement already satisfied: llvmlite&lt;0.42,&gt;=0.41.0dev0 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.41.1)\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nRequirement already satisfied: mlflow==2.2.2 in /databricks/python3/lib/python3.8/site-packages (2.2.2)\nRequirement already satisfied: scipy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.6.2)\nRequirement already satisfied: requests&lt;3,&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.32.3)\nRequirement already satisfied: entrypoints&lt;1 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.3)\nRequirement already satisfied: markdown&lt;4,&gt;=3.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.7)\nRequirement already satisfied: cloudpickle&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.2.1)\nRequirement already satisfied: scikit-learn&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.0.2)\nRequirement already satisfied: shap&lt;1,&gt;=0.40 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.44.1)\nRequirement already satisfied: pytz&lt;2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2020.5)\nRequirement already satisfied: pyyaml&lt;7,&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.0.2)\nRequirement already satisfied: docker&lt;7,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.1.3)\nRequirement already satisfied: pandas&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.4.4)\nRequirement already satisfied: querystring-parser&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.2.4)\nRequirement already satisfied: numpy&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.22.4)\nRequirement already satisfied: importlib-metadata!=4.7.0,&lt;7,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (6.11.0)\nRequirement already satisfied: protobuf&lt;5,&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.17.2)\nRequirement already satisfied: pyarrow&lt;12,&gt;=4.0.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (4.0.0)\nRequirement already satisfied: Flask&lt;3 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.3.3)\nRequirement already satisfied: packaging&lt;24 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (23.2)\nRequirement already satisfied: databricks-cli&lt;1,&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.18.0)\nRequirement already satisfied: alembic&lt;2 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (1.13.3)\nRequirement already satisfied: sqlparse&lt;1,&gt;=0.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (0.5.1)\nRequirement already satisfied: matplotlib&lt;4 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.4.2)\nRequirement already satisfied: gunicorn&lt;21 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (20.1.0)\nRequirement already satisfied: Jinja2&lt;4,&gt;=2.11 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.1.4)\nRequirement already satisfied: gitpython&lt;4,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (3.1.43)\nRequirement already satisfied: click&lt;9,&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (8.1.7)\nRequirement already satisfied: sqlalchemy&lt;3,&gt;=1.4.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow==2.2.2) (2.0.35)\nRequirement already satisfied: importlib-resources in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (6.4.5)\nRequirement already satisfied: typing-extensions&gt;=4 in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (4.12.2)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic&lt;2-&gt;mlflow==2.2.2) (1.3.5)\nRequirement already satisfied: oauthlib&gt;=3.1.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (3.2.2)\nRequirement already satisfied: pyjwt&gt;=1.7.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (2.9.0)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.26.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (1.26.15)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (0.9.0)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&lt;1,&gt;=0.8.7-&gt;mlflow==2.2.2) (1.15.0)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&lt;7,&gt;=4.0.0-&gt;mlflow==2.2.2) (1.8.0)\nRequirement already satisfied: blinker&gt;=1.6.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (1.8.2)\nRequirement already satisfied: Werkzeug&gt;=2.3.7 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (3.0.4)\nRequirement already satisfied: itsdangerous&gt;=2.1.2 in /databricks/python3/lib/python3.8/site-packages (from Flask&lt;3-&gt;mlflow==2.2.2) (2.2.0)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&lt;4,&gt;=2.1.0-&gt;mlflow==2.2.2) (4.0.11)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&lt;4,&gt;=2.1.0-&gt;mlflow==2.2.2) (5.0.1)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn&lt;21-&gt;mlflow==2.2.2) (52.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&lt;7,&gt;=3.7.0-&gt;mlflow==2.2.2) (3.20.2)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&lt;4,&gt;=2.11-&gt;mlflow==2.2.2) (2.1.5)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (0.10.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (8.2.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (2.4.7)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (1.3.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4-&gt;mlflow==2.2.2) (2.8.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (2020.12.5)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (2.10)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.17.3-&gt;mlflow==2.2.2) (3.3.2)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow==2.2.2) (1.0.1)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn&lt;2-&gt;mlflow==2.2.2) (2.1.0)\nRequirement already satisfied: numba in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.58.1)\nRequirement already satisfied: tqdm&gt;=4.27.0 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (4.66.5)\nRequirement already satisfied: slicer==0.0.7 in /databricks/python3/lib/python3.8/site-packages (from shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.0.7)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.8/site-packages (from sqlalchemy&lt;3,&gt;=1.4.0-&gt;mlflow==2.2.2) (3.1.1)\nRequirement already satisfied: llvmlite&lt;0.42,&gt;=0.41.0dev0 in /databricks/python3/lib/python3.8/site-packages (from numba-&gt;shap&lt;1,&gt;=0.40-&gt;mlflow==2.2.2) (0.41.1)\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install mlflow==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7afa20e3-5a09-41c1-b29d-7d6969648dad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "387ce436-cbb0-4a32-b252-abdbdd677eee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from sys import version_info\n",
    "import cloudpickle\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import logging\n",
    "import warnings\n",
    "from mlflow import MlflowException\n",
    "from mlflow.client import MlflowClient\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60966f75-cb59-456e-ab13-d5c9f434fc08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sys.path.append(os.path.abspath('/Workspace/Repos/manik@surge.global/phg-data-mlsys/src'))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe4f676-776e-4148-9104-ce1690201e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENV = getArgument(\"env_stage\")\n",
    "\n",
    "REPOPATH = \"/Workspace/Repos/manik@surge.global/phg-data-mlsys/src\"\n",
    "\n",
    "cluster_name = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "\n",
    "if (ENV == \"dev\") and (\"dev\" in cluster_name):\n",
    "    print(f\"Loading phgml package from repo {REPOPATH}\")\n",
    "    sys.path.append(os.path.abspath(REPOPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d12133c-b274-4ba3-ac0d-db521fc44034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from phgml.models.xgboost_model import XGBMultiStepPredictor\n",
    "from phgml.models.autogluon_model import AutoGluonModel, AGMlflowModel\n",
    "from phgml.models.lightgbm_model import LightGBMModel, LGBMMlflowModel\n",
    "# from phgml.pipeline.training import train_wrapper\n",
    "from phgml.data.processing_distr_ca import (\n",
    "    filter_train_data,\n",
    "    filter_test_data,\n",
    "    remove_padded_cols,\n",
    ")\n",
    "from phgml.reporting.output_metrics import *\n",
    "from phgml.data.data_types import (\n",
    "    revenue_preprocessed_schema,\n",
    "    rooms_preprocessed_schema,\n",
    "    training_output_schema,\n",
    ")\n",
    "from phgml.reporting.logging import get_logging_path, get_logging_filename, get_dbx_logger\n",
    "from phgml.reporting.report_results import get_output_df, correct_prediction_list\n",
    "from phgml.data.config import EnvironmentConfig, ForecastingHotelConfigProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee392d0-30b2-459f-a10b-6a56a07a9bd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Disable adaptrive query optimization\n",
    "# Adaptive query optimization groups together smaller tasks into a larger tasks.\n",
    "# This may result in limited parallelism if the parallel inference tasks are deemed to be too small by the query optimizer\n",
    "# We are diableing AQE here to circumevent this limitation on parallelism\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41b9a4fc-5437-4583-9c82-eae4a7d5fa21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def str_to_lst(value):\n",
    "    if value == \"\":\n",
    "        return []\n",
    "    elif \",\" in value:\n",
    "        hotels = value.split(\",\")\n",
    "        return hotels\n",
    "\n",
    "    return [value]\n",
    "\n",
    "\n",
    "def str_to_bool(value):\n",
    "    FALSE_VALUES = [\"false\", \"no\", \"0\"]\n",
    "    TRUE_VALUES = [\"true\", \"yes\", \"1\"]\n",
    "    lvalue = str(value).lower()\n",
    "    if lvalue in (FALSE_VALUES):\n",
    "        return False\n",
    "    if lvalue in (TRUE_VALUES):\n",
    "        return True\n",
    "    raise Exception(\n",
    "        \"String value should be one of {}, but got '{}'.\".format(\n",
    "            FALSE_VALUES + TRUE_VALUES, value\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_model_tags(model_tags_str):\n",
    "    ''' A Validation for the model tag text through databricks utility'''\n",
    "    valid_pattern = r'(\\w+:\\w+)'\n",
    "    invalid_pattern = r'[^:,\\w\\s]'\n",
    "    str_cpy=model_tags_str.replace(\" \", '')\n",
    "\n",
    "    not_allowed_symbols = re.findall(pattern=invalid_pattern, string=str_cpy)\n",
    "    if len(not_allowed_symbols)>0:\n",
    "        raise ValueError('''Unwanted characters detected. Allowed characters are colon(:), comma(,), word characters and white space characters\n",
    "                            Please specify key values pairs as key1:value1,key2:value2\n",
    "                        ''')\n",
    "    else:\n",
    "        matching_pairs = re.findall(pattern=valid_pattern, string=str_cpy)\n",
    "\n",
    "        for matching_str in matching_pairs:\n",
    "            str_cpy = str_cpy.replace(matching_str,'')\n",
    "        str_cpy = str_cpy.replace(',','')\n",
    "        \n",
    "        if len(str_cpy)>0:\n",
    "            raise ValueError('''unmatched string components detected. please check the specified string\n",
    "                             Please specify key values pairs as key1:value1,key2:value2\n",
    "                             ''')\n",
    "        \n",
    "    return {key:value for key,value in map(lambda x: x.split(':'),matching_pairs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d531c3db-59f3-40b5-b01b-e5da7cf1d224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_root = \"/dbfs/mnt/extractionlogs/synxis\"\n",
    "processing_timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e92e3b65-4369-4a84-b539-0a74e5ee4386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">model tags dict:  {}\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">model tags dict:  {}\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "REVENUE_COL = \"_reservationRevenuePerRoomUSD\"\n",
    "ROOMS_COL = \"rooms\"\n",
    "PIPELINE = \"TRAINING\"\n",
    "\n",
    "WITHOUT_PMS = str_to_bool(getArgument(\"exclude_pms\"))\n",
    "IS_USD_CURRENCY = str_to_bool(getArgument(\"is_usd_currency\"))\n",
    "TARGET_TYPE = getArgument(\"target_type\")\n",
    "\n",
    "MODEL_TAGS_DCT = get_model_tags(getArgument(\"model_tags\"))\n",
    "print('model tags dict: ',MODEL_TAGS_DCT)\n",
    "\n",
    "### The start of the model data\n",
    "MODEL_START_DATE = pd.to_datetime(\"2018-10-01\")\n",
    "\n",
    "COVID_START_DATE = pd.to_datetime(\"2020-03-01\")\n",
    "COVID_END_DATE = pd.to_datetime(\"2021-08-01\")\n",
    "\n",
    "CALC_UNCERTAINTY = True\n",
    "# MODEL_TYPE = \"XGB\"  # Use \"AG\" to try out the auto gloun approach\n",
    "MODEL_TYPE = \"AG\"\n",
    "\n",
    "LEAD_WINDOW = 60\n",
    "PREDICTION_HORIZON = 30\n",
    "\n",
    "ML_EXPERIMENT_ID = 609933091443417\n",
    "\n",
    "lead_window_start_days = 14\n",
    "lead_window_end_days = 60\n",
    "prediction_horizon = 14\n",
    "LAG_NUMBERS = list(map(int,str_to_lst(getArgument('lag_numbers'))))\n",
    "\n",
    "\n",
    "SAVE_MODEL = False\n",
    "SAVE_METRICS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf338b5-ffb9-4615-b115-d37505a539db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Config data relevant to this pipeline\n",
    "env_config = EnvironmentConfig(env=ENV, target=TARGET_TYPE, spark=spark, is_usd_currency=IS_USD_CURRENCY)\n",
    "forecasting_config_provider = ForecastingHotelConfigProvider(spark=spark,env=ENV)\n",
    "target_column = env_config.target_column\n",
    "schema = training_output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc81d44-92e8-4e6e-abd2-43856edbe5c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger= get_dbx_logger(\n",
    "    pipeline=PIPELINE,\n",
    "    task_type=TARGET_TYPE,\n",
    "    exclude_pms=WITHOUT_PMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eedeadb-8909-4a73-97e2-375f160c619d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(f\"Processing data for target type: {TARGET_TYPE} : {target_column}\")\n",
    "logger.info(f\"Excluding PMS data? {WITHOUT_PMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c14102b-fc2d-4b8d-8af5-4bbb8a9b42be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Removed forecast training wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3f95d2-191c-4d1e-8dd8-fc7cc22c76e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(f\"Loading data from testing_data.pp_ff_preprocess_rv\")\n",
    "df = spark.sql(f\"select * from testing_data.pp_ff_preprocess_rv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a744589b-c113-454f-ac96-58b039f71335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df.count() <= 0:\n",
    "    logger.error(\"The loaded training dataset is empty.\")\n",
    "    logger.info(\"Terminting the pipeline execution\")\n",
    "    raise Exception(\"The loaded training dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d9e69f-2400-4311-85fb-5629270f9fa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from phgml.models.base_model import BaseModel\n",
    "from phgml.models.model_strategy import BaseStrategy\n",
    "from phgml.models.model_strategy import StrategyLGBM, StrategyAG, StrategyLGBMFarField\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "from sys import version_info\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from typing import Optional, Tuple, Union, List, Dict, Any, Callable\n",
    "import numpy.typing as npt\n",
    "import re\n",
    "\n",
    "__all__ = [\"ModelWrapper\", \"ModelWrapperMlflowModel\", \"ModelWrapperFarField\"]\n",
    "\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(\n",
    "    major=version_info.major, minor=version_info.minor, micro=version_info.micro\n",
    ")\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        \"python={}\".format(PYTHON_VERSION),\n",
    "        \"pip\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"mlflow\",\n",
    "                \"lightgbm\",\n",
    "                \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"model_wrapper_env\",\n",
    "}\n",
    "\n",
    "\n",
    "class ModelWrapper(BaseModel):\n",
    "    \"\"\"Custom class which wraps a model type to generate\n",
    "    predictions in a timeseries format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cd_axis_max_lags: int,\n",
    "        static_cols: List[str],\n",
    "        model_strategy: BaseStrategy,\n",
    "        is_auto_reg: bool = False,\n",
    "        is_ca3_training: bool = True,\n",
    "        prediction_horizon: int = 28,\n",
    "        lag_numbers: List[int] = [1, 7, 14, 28],\n",
    "        quantiles: List[float] = [0.5],\n",
    "        mlflow_run_id: Optional[str] = None,\n",
    "        hotel_id: Optional[str] = None,\n",
    "        version: Optional[Union[str, int]] = None,\n",
    "        stage: Optional[str] = None,\n",
    "        target_type: str = \"REVENUE\",\n",
    "        exclude_pms: bool = False,\n",
    "        save_models: bool = True,\n",
    "        local_root_dir: Optional[str] = None,\n",
    "        model_type: str = \"MODELWRAPPER\",\n",
    "        model_name_prefix: Optional[str] = None,\n",
    "        meta_data: Dict[str, Any] = {},\n",
    "        n_cd_lags: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model_type=model_strategy.model_type,\n",
    "            prediction_horizon=prediction_horizon,\n",
    "            lag_numbers=lag_numbers,\n",
    "            quantiles=quantiles,\n",
    "            mlflow_run_id=mlflow_run_id,\n",
    "            hotel_id=hotel_id,\n",
    "            version=version,\n",
    "            stage=stage,\n",
    "            target_type=target_type,\n",
    "            exclude_pms=exclude_pms,\n",
    "            save_models=save_models,\n",
    "            local_root_dir=local_root_dir,\n",
    "            model_name_prefix=model_name_prefix,\n",
    "            meta_data=meta_data,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.quantile_levels.sort()\n",
    "        self.cd_axis_max_lags = cd_axis_max_lags\n",
    "        self.sd_axis_lag_prefix = \"lag\"\n",
    "        self.static_cols = static_cols\n",
    "        self.n_cd_lags = n_cd_lags\n",
    "        self.target_suffix = \"_tgt\"\n",
    "        self.is_auto_reg = is_auto_reg\n",
    "\n",
    "        self.model_strategy = model_strategy\n",
    "        self.model_type = self.model_strategy.model_type\n",
    "        self.all_cd_cols = [\n",
    "            f\"{self.target_prefix}{i}\" for i in range(self.cd_axis_max_lags + 1)\n",
    "        ]\n",
    "        self.is_ca3_training = is_ca3_training\n",
    "\n",
    "        # initializing targets variables\n",
    "        self.target_cols: Dict[int, List[str]] = {}\n",
    "\n",
    "        # initializing feature variables\n",
    "        self.feature_cols: Dict[int, List[str]] = {}\n",
    "\n",
    "        self.envs = [\"dev\", \"qa\", \"prod\"]\n",
    "\n",
    "        if 0.5 not in self.quantile_levels:\n",
    "            raise ValueError(\n",
    "                \"median quantile (0.5) is not included in the quantile_levels. please ensure that its included\"\n",
    "            )\n",
    "\n",
    "    def save_model(self) -> None:\n",
    "        \"\"\"Saves the models in the local directory, which will then be logged as artifacts in MLflow\"\"\"\n",
    "        if os.path.exists(self.local_root):\n",
    "            self.clean()\n",
    "\n",
    "        os.makedirs(self.local_dir)\n",
    "        with open(self.local_path, \"wb\") as pkl_file:\n",
    "            pickle.dump(obj=self, file=pkl_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def change_current_env_tags(self, incoming_tags: Dict[str, str]):\n",
    "\n",
    "        env_model_tag_keys = set([f\"model_stage_{env}\" for env in self.envs])\n",
    "        incoming_tags_keys = set(incoming_tags.keys())\n",
    "\n",
    "        tags_detected = env_model_tag_keys.intersection(incoming_tags_keys)\n",
    "\n",
    "        if len(tags_detected) > 0:\n",
    "            client = MlflowClient()\n",
    "            all_registered_models_info = client.search_model_versions(\n",
    "                f\"name ='{self.get_model_name()}'\"\n",
    "            )\n",
    "            # sorting the model meta data list by version number of the considered model name in descending order\n",
    "            sorted_model_versions = sorted(\n",
    "                all_registered_models_info, key=lambda x: int(x.version), reverse=True\n",
    "            )\n",
    "\n",
    "            for version_meta in sorted_model_versions:\n",
    "                for env_tag in tags_detected:\n",
    "\n",
    "                    if (incoming_tags[env_tag] == \"yes\") and (\n",
    "                        version_meta.tags.get(env_tag) == \"yes\"\n",
    "                    ):\n",
    "                        client.set_model_version_tag(\n",
    "                            name=self.get_model_name(),\n",
    "                            version=str(version_meta.version),\n",
    "                            key=env_tag,\n",
    "                            value=\"no\",\n",
    "                        )\n",
    "\n",
    "    def log_models(self) -> None:\n",
    "        \"\"\"Carries out the mlflow model registry procedures\"\"\"\n",
    "        print(\"Starting model logging\")\n",
    "        self.save_model()\n",
    "\n",
    "        modelpath = self.get_model_log_path()\n",
    "        print(\"Logging model\")\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=self.get_model_log_path(),\n",
    "            python_model=ModelWrapperMlflowModel(),\n",
    "            artifacts=self.artifacts,\n",
    "            conda_env=conda_env,\n",
    "        )\n",
    "\n",
    "        # enforcing lower case for env based string keys and values\n",
    "        decap_meta_data = {}\n",
    "        for key, value in self.meta_data.items():\n",
    "            env_str_match = re.findall(pattern=f\"({'|'.join(self.envs)})\", string=key)\n",
    "            if len(env_str_match) > 0:\n",
    "                decap_meta_data[key.lower()] = (\n",
    "                    value.lower() if isinstance(value, str) else value\n",
    "                )\n",
    "            else:\n",
    "                decap_meta_data[key] = value\n",
    "\n",
    "        self.meta_data = decap_meta_data\n",
    "\n",
    "        self.change_current_env_tags(self.meta_data)\n",
    "\n",
    "        print(\"Registering model\")\n",
    "        result = mlflow.register_model(\n",
    "            self.get_model_register_path(),\n",
    "            self.get_model_name(),\n",
    "            tags=self.meta_data,\n",
    "        )\n",
    "\n",
    "    def clean(self) -> None:\n",
    "        if os.path.exists(self.local_root):\n",
    "            shutil.rmtree(self.local_root)\n",
    "\n",
    "    def load_pyfunc_model(\n",
    "        self, dst_path: Optional[str] = None, tag: Optional[Union[str, int]] = None\n",
    "    ) -> mlflow.pyfunc.PyFuncModel:\n",
    "        \"\"\"Load and return the pyfunc model from the MLFlow model repository\n",
    "\n",
    "        Args:\n",
    "            dst_path (str, optional): Destination path to save the loaded model.\n",
    "                                      If not provided the files will be saved in the local_root path.\n",
    "                                      Defaults to None.\n",
    "            tag (str, optional): Tag to specify the version or model stage to be loaded.\n",
    "                                 If not provided the latest model version will be loaded.\n",
    "                                Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            mlflow.pyfunc.model : pyfunc model\n",
    "        \"\"\"\n",
    "        # self.local_dir = dst_path\n",
    "        print(f\"Loading model {self.get_model_uri()}\")\n",
    "\n",
    "        if dst_path is not None:\n",
    "            self.local_root = dst_path\n",
    "\n",
    "        if os.path.exists(self.local_root):\n",
    "            self.clean()\n",
    "\n",
    "        os.mkdir(self.local_root)\n",
    "\n",
    "        model = mlflow.pyfunc.load_model(\n",
    "            self.get_model_uri(tag=tag), dst_path=self.local_root\n",
    "        )\n",
    "\n",
    "        self.run_id = model._model_meta.run_id\n",
    "\n",
    "        # following is a bit of a round about way to set local_dir\n",
    "        # having the run id in the directory name is a bit troublesome as the run id is not available to us when we create the autogluon object\n",
    "        # TODO make sure to remove the run id from the local_dir and include either or both task_type/exclude_pms\n",
    "        # TODO make sure to set the local_dir consistently for both training and inference tasks\n",
    "        # self.local_dir = \"/ag_models/\"\n",
    "\n",
    "        # if self.exclude_pms:\n",
    "        #     self.local_dir = f\"ag_models_{self.hotel_id}_{self.run_id}/\"\n",
    "\n",
    "        # os.rename(\"artifacts\",self.local_dir)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_filtered_data(\n",
    "        self, data: pd.DataFrame, day_ahead: int\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        target_columns = self.all_cd_cols[:day_ahead]\n",
    "        target_columns = list(\n",
    "            map(lambda target: target + self.target_suffix, target_columns)\n",
    "        )\n",
    "\n",
    "        # original target order\n",
    "        target_columns_orig = target_columns.copy()\n",
    "        target_columns.reverse()\n",
    "\n",
    "        cd_axis_lag_columns = self.all_cd_cols[day_ahead:]\n",
    "        if self.n_cd_lags != None:\n",
    "            cd_axis_lag_columns = cd_axis_lag_columns[: self.n_cd_lags]\n",
    "\n",
    "        sd_axis_lag_columns = [\n",
    "            f\"{self.sd_axis_lag_prefix}{SD_lag}\"\n",
    "            for SD_lag in self.lag_numbers\n",
    "            if SD_lag > day_ahead\n",
    "        ]\n",
    "\n",
    "        # assigning target and feature variables corresponding to the particular day ahead. This will be retrieved through the attributes in the inference phase.\n",
    "        self.target_cols[day_ahead] = target_columns\n",
    "        self.feature_cols[day_ahead] = (\n",
    "            cd_axis_lag_columns + sd_axis_lag_columns + self.static_cols\n",
    "        )\n",
    "\n",
    "        if self.is_ca3_training:\n",
    "            # Condition helps us get the specific entry for the cancellation day index\n",
    "            condition = data[\"forecast_index\"] == (day_ahead - 1)\n",
    "            filt_data = data[condition].copy()\n",
    "        else:\n",
    "            filt_data = data.copy()\n",
    "\n",
    "        x_data = filt_data[self.feature_cols[day_ahead]]\n",
    "        y_data = filt_data[self.target_cols[day_ahead]]\n",
    "\n",
    "        return (\n",
    "            x_data,\n",
    "            y_data,\n",
    "            filt_data[target_columns_orig + self.feature_cols[day_ahead]],\n",
    "        )\n",
    "\n",
    "    def train_inner(self, train_data: pd.DataFrame, day_ahead: int):\n",
    "        x_train, y_train, xy_train = self.get_filtered_data(\n",
    "            data=train_data, day_ahead=day_ahead\n",
    "        )\n",
    "\n",
    "        reg_obj = self.model_strategy(\n",
    "            quantile_levels=self.quantile_levels,\n",
    "            day_ahead=day_ahead,\n",
    "            cd_axis_targets=self.target_cols[day_ahead],\n",
    "            path=self.local_dir,\n",
    "            is_auto_reg=self.is_auto_reg,\n",
    "        )  # type: ignore\n",
    "        reg_obj._fit(xy_train)\n",
    "\n",
    "        # self.models[day_ahead] = reg_obj\n",
    "\n",
    "        return day_ahead, reg_obj\n",
    "\n",
    "    def train(self, train_data: pd.DataFrame, n_threads: int) -> None:\n",
    "        \"\"\"\n",
    "        trains models for each day ahead quantile predictions and  relevant\n",
    "        to the specified prediction_horizon value and the specific quantile\n",
    "        levels.\n",
    "\n",
    "        parameters:\n",
    "            train_data = training data with the booking pace lags, stay date lags or\n",
    "                    other features such as date features.\n",
    "\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "            future_to_target = {executor.submit(\n",
    "                self.train_inner, train_data, day_ahead): day_ahead for day_ahead in range(1, self.prediction_horizon + 1)}\n",
    "            \n",
    "            for future in as_completed(future_to_target):\n",
    "                # day_ahead = future_to_target[future]\n",
    "                # print(day_ahead)\n",
    "                try:\n",
    "                    day_ahead, reg_obj = future.result()\n",
    "                except Exception as exc:\n",
    "                    print(exc)\n",
    "                else:\n",
    "                    self.models[day_ahead] = reg_obj\n",
    "\n",
    "        # for day_ahead in range(1, self.prediction_horizon + 1):\n",
    "        #     day_ahead, reg_obj = self.train_inner(train_data, day_ahead)\n",
    "        #     print(day_ahead, reg_obj)\n",
    "\n",
    "        #     self.models[day_ahead] = reg_obj\n",
    "\n",
    "        # for day_ahead in range(1, self.prediction_horizon + 1):\n",
    "        #     print(\"\\tday ahead: \", day_ahead)\n",
    "        #     x_train, y_train, xy_train = self.get_filtered_data(\n",
    "        #         data=train_data, day_ahead=day_ahead\n",
    "        #     )\n",
    "\n",
    "        #     reg_obj = self.model_strategy(\n",
    "        #         quantile_levels=self.quantile_levels,\n",
    "        #         day_ahead=day_ahead,\n",
    "        #         cd_axis_targets=self.target_cols[day_ahead],\n",
    "        #         path=self.local_dir,\n",
    "        #         is_auto_reg=self.is_auto_reg,\n",
    "        #     )  # type: ignore\n",
    "        #     reg_obj._fit(xy_train)\n",
    "\n",
    "        #     self.models[day_ahead] = reg_obj\n",
    "\n",
    "        # if self.do_save_models:\n",
    "        #     self.log_models()\n",
    "\n",
    "    def predict(\n",
    "        self, test_data: pd.DataFrame\n",
    "    ) -> Dict[Union[str, float], Union[List[npt.NDArray], List[pd.Series]]]:\n",
    "        \"\"\"generating quantile predictions for the test data provided. test_data\n",
    "        should be provided which aligns with the prediction_horizon. If\n",
    "        test_data has less rows than the prediction_horizon, then the length\n",
    "        of the test_data will be considered as the prediction horizon.\n",
    "\n",
    "        eg: if prediction_horizon= 28, ideally test_data should have 28 rows\n",
    "            which are relevant for 28 stay dates.\n",
    "\n",
    "        parameters:\n",
    "            test_data = test data which aligns with the prediction horizon.\n",
    "                        rows of test_data <= prediction_horizon.\n",
    "\n",
    "        Returns: Lists with actual values and corresponding predicted values along the booking axis leading upto the\n",
    "          relevant stay date ahead\n",
    "        \"\"\"\n",
    "        output_pred: Dict[\n",
    "            Union[str, float], Union[List[npt.NDArray], List[pd.Series]]\n",
    "        ] = {}\n",
    "\n",
    "        for day_ahead in range(1, self.prediction_horizon + 1):\n",
    "            test_idx = day_ahead - 1\n",
    "\n",
    "            try:\n",
    "                needed_test_data = test_data[test_data.day_ahead == day_ahead].iloc[0]\n",
    "            except IndexError as e:\n",
    "                days_str = \"days\" if day_ahead > 1 else \"day\"\n",
    "\n",
    "                print(f\"Error when predicting {day_ahead} {days_str} ahead\")\n",
    "                print(f\"Encountered error {e}\")\n",
    "                print(\"Skipping this row\")\n",
    "                continue\n",
    "\n",
    "            x_test = needed_test_data[self.feature_cols[day_ahead]]\n",
    "            y_test = needed_test_data[self.target_cols[day_ahead]]\n",
    "\n",
    "            predictor = self.models[day_ahead]\n",
    "            y_pred_dct = predictor._predict(x_test)\n",
    "\n",
    "            if output_pred.get(\"y_test\") == None:\n",
    "                output_pred[\"y_test\"] = [y_test]\n",
    "            else:\n",
    "                output_pred[\"y_test\"] += [y_test]\n",
    "\n",
    "            for qtile in self.quantile_levels:\n",
    "                if output_pred.get(qtile) == None:\n",
    "                    output_pred[qtile] = [y_pred_dct[qtile][0]]\n",
    "                else:\n",
    "                    output_pred[qtile] += [y_pred_dct[qtile][0]]\n",
    "\n",
    "        return output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a683b52e-ce42-4dee-9675-b3afa8317157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_wrapper(\n",
    "    target_type: str,\n",
    "    ml_experiment_id: str,\n",
    "    exclude_pms: bool,\n",
    "    calc_uncertainty: bool,\n",
    "    hotel_config_provider: ForecastingHotelConfigProvider,\n",
    "    processing_timestamp: datetime,\n",
    "    save_models: bool,\n",
    "    save_metrics: bool,\n",
    "    lag_numbers: List[int],\n",
    "    model_tags: dict = None,\n",
    "    n_threads: int = 4,\n",
    ") -> Callable:\n",
    "    def train_data_models(df):\n",
    "        static_cols_ = [\n",
    "            \"year\",\n",
    "            \"quarter_of_year\",\n",
    "            \"month_of_year\",\n",
    "            \"week_of_year\",\n",
    "            \"day_of_year\",\n",
    "            \"month_of_quarter\",\n",
    "            \"week_of_quarter\",\n",
    "            \"day_of_quarter\",\n",
    "            \"week_of_month\",\n",
    "            \"day_of_month\",\n",
    "            \"holiday\",\n",
    "            \"day_of_week_0\",\n",
    "            \"day_of_week_1\",\n",
    "            \"day_of_week_2\",\n",
    "            \"day_of_week_3\",\n",
    "            \"day_of_week_4\",\n",
    "            \"day_of_week_5\",\n",
    "            \"day_of_week_6\",\n",
    "        ]\n",
    "\n",
    "        logger = get_dbx_logger(\"PHGML\")\n",
    "\n",
    "        trainer = None\n",
    "        hotel_id = df[\"HotelID\"].iloc[0]\n",
    "        hotel_config = hotel_config_provider.get_config(hotel_id)\n",
    "        model_type = hotel_config.training_model_name\n",
    "\n",
    "        max_lead_window = 100\n",
    "\n",
    "        if target_type == \"REVENUE\":\n",
    "            col_prefix = \"RV\"\n",
    "        elif target_type == \"ROOMS\":\n",
    "            col_prefix = \"RM\"\n",
    "\n",
    "        df = remove_padded_cols(\n",
    "            df, hotel_config.lead_window, max_lead_window, col_prefix\n",
    "        )\n",
    "\n",
    "        test_partition_end = df[\"_StayDates\"].max()\n",
    "        test_partition_start = test_partition_end - pd.Timedelta(\n",
    "            hotel_config.training_length, \"D\"\n",
    "        )\n",
    "        metadata_dict = {\n",
    "            \"last_trained_date\": str(\n",
    "                test_partition_start - pd.Timedelta(hotel_config.training_length, \"D\")\n",
    "            ),\n",
    "            \"training_length\": hotel_config.training_length,\n",
    "            \"inference_length\": hotel_config.inference_length,\n",
    "        }\n",
    "        metadata_dict.update(model_tags)\n",
    "\n",
    "        logger.debug(f\"{hotel_id}:Filter train data\")\n",
    "        dftrain = filter_train_data(df, test_partition_start)\n",
    "\n",
    "        logger.debug(f\"{hotel_id}:Filter test data\")\n",
    "        dftest = filter_test_data(\n",
    "            df,\n",
    "            test_partition_start=test_partition_start,\n",
    "            test_partition_end=test_partition_end,\n",
    "        )\n",
    "        dftest[\"day_ahead\"] = (dftest[\"_StayDates\"] - test_partition_start).dt.days\n",
    "        dftest = dftest[dftest.forecast_index == (dftest.day_ahead - 1)]\n",
    "\n",
    "        model_version = 1\n",
    "        model_stage = \"Staging\"\n",
    "        model_name = None\n",
    "\n",
    "        pms = \"PMS\"\n",
    "        if exclude_pms:\n",
    "            pms = \"NOPMS\"\n",
    "\n",
    "        with mlflow.start_run(\n",
    "            experiment_id=ml_experiment_id,\n",
    "            run_name=f\"{model_type}-{target_type}-{pms}-{hotel_id}-{hotel_config.hotel_name}\",\n",
    "        ) as run:\n",
    "            run_id = run.info.run_id\n",
    "\n",
    "            if model_type == \"AUTOGLUON\":\n",
    "                trainer = ModelWrapper(\n",
    "                    model_strategy=StrategyAG,\n",
    "                    is_auto_reg=True,\n",
    "                    prediction_horizon=hotel_config.training_length,\n",
    "                    mlflow_run_id=run_id,\n",
    "                    hotel_id=hotel_id,\n",
    "                    save_models=save_models,\n",
    "                    target_type=target_type,\n",
    "                    exclude_pms=exclude_pms,\n",
    "                    meta_data=metadata_dict,\n",
    "                    cd_axis_max_lags=99,\n",
    "                    static_cols=static_cols_,\n",
    "                    quantiles=[0.1, 0.5, 0.9],\n",
    "                )\n",
    "            elif model_type == \"LIGHTGBM\":\n",
    "                trainer = ModelWrapper(\n",
    "                    model_strategy=StrategyLGBM,\n",
    "                    prediction_horizon=hotel_config.training_length,\n",
    "                    mlflow_run_id=run_id,\n",
    "                    hotel_id=hotel_id,\n",
    "                    save_models=save_models,\n",
    "                    target_type=target_type,\n",
    "                    exclude_pms=exclude_pms,\n",
    "                    meta_data=metadata_dict,\n",
    "                    cd_axis_max_lags=99,\n",
    "                    static_cols=static_cols_,\n",
    "                    quantiles=[0.1, 0.5, 0.9],\n",
    "                )\n",
    "\n",
    "            model_name = trainer.get_model_name()\n",
    "            output_df = pd.DataFrame()\n",
    "            try:\n",
    "                logger.info(f\"{hotel_id}:Training model\")\n",
    "                trainer.train(dftrain, n_threads)\n",
    "\n",
    "                logger.info(f\"{hotel_id}:Completed training\")\n",
    "                logger.info(f\"{hotel_id}:Start prediction\")\n",
    "\n",
    "                output_dct = trainer.predict(dftest)\n",
    "                y_pred_lst, y_test_lst, y_upper_lst, y_lower_lst = (\n",
    "                    output_dct[0.5],\n",
    "                    output_dct[\"y_test\"],\n",
    "                    output_dct[0.9],\n",
    "                    output_dct[0.1],\n",
    "                )\n",
    "\n",
    "                predicted_stays = [i[-1] for i in y_pred_lst]\n",
    "                observed_stays = [i.values[-1] for i in y_test_lst]\n",
    "                if calc_uncertainty:\n",
    "                    upper_stays = [i[-1] for i in y_upper_lst]\n",
    "                    lower_stays = [i[-1] for i in y_lower_lst]\n",
    "\n",
    "                if save_metrics:\n",
    "                    log_metrics_stays(observed_stays, predicted_stays, trainer)\n",
    "\n",
    "                report_metrics_stays(observed_stays, predicted_stays)\n",
    "\n",
    "                del dftrain\n",
    "                del dftest\n",
    "\n",
    "                output_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"HotelID\": [hotel_id],\n",
    "                        \"run_id\": [run_id],\n",
    "                        \"model_version\": [model_version],\n",
    "                        \"timestamp\": [processing_timestamp],\n",
    "                        \"pms_sync_off\": [exclude_pms],\n",
    "                        \"model_name\": [model_name],\n",
    "                        \"status\": \"complete\",\n",
    "                        \"message\": f\"Successfully trained {hotel_id}\",\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                empty = pd.DataFrame(\n",
    "                    {\n",
    "                        \"HotelID\": [hotel_id],\n",
    "                        \"run_id\": [run_id],\n",
    "                        \"model_version\": [model_version],\n",
    "                        \"timestamp\": [pd.Timestamp(\"1900-01-01\")],\n",
    "                        \"pms_sync_off\": [exclude_pms],\n",
    "                        \"model_name\": [model_name],\n",
    "                        \"status\": \"incomplete\",\n",
    "                        \"message\": str(e),\n",
    "                    }\n",
    "                )\n",
    "                return empty\n",
    "\n",
    "            finally:\n",
    "                if (model_type == \"AUTOGLUON\") and (trainer is not None):\n",
    "                    trainer.clean()\n",
    "\n",
    "        return output_df\n",
    "\n",
    "    return train_data_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6dacd05-02c1-43da-84da-f89c40232671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[65]: (False, False)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[65]: (False, False)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_MODEL, SAVE_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c12e861-3088-4bb3-aba1-0f5a87cd2aa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group the data by hotel id and execute the trainings in parallel\n",
    "logger.info(\"Starting parallel training\")\n",
    "\n",
    "output_df = df.groupby(\"HotelID\").applyInPandas(\n",
    "    train_wrapper(\n",
    "        target_type=TARGET_TYPE,\n",
    "        ml_experiment_id=ML_EXPERIMENT_ID,\n",
    "        exclude_pms=WITHOUT_PMS,\n",
    "        calc_uncertainty=CALC_UNCERTAINTY,\n",
    "        hotel_config_provider=forecasting_config_provider,\n",
    "        processing_timestamp=processing_timestamp,\n",
    "        save_models=SAVE_MODEL,\n",
    "        save_metrics=SAVE_METRICS,\n",
    "        lag_numbers=LAG_NUMBERS,\n",
    "        model_tags=MODEL_TAGS_DCT\n",
    "    ),\n",
    "    schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d71fcb3f-340e-4db3-92e3-7fea528e9447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>HotelID</th><th>run_id</th><th>model_version</th><th>timestamp</th><th>pms_sync_off</th><th>model_name</th><th>status</th><th>message</th></tr></thead><tbody><tr><td>71999</td><td>3c5b82d9b6874242b8bb6cc0d148de9e</td><td>1</td><td>2024-10-01T18:28:26.994+0000</td><td>false</td><td>71999_REVENUE_PMS_LGBM_model</td><td>complete</td><td>Successfully trained 71999</td></tr><tr><td>10443</td><td>eb0231c82a7743a08ac2b8afa658ad5b</td><td>1</td><td>2024-10-01T18:28:26.994+0000</td><td>false</td><td>10443_REVENUE_PMS_LGBM_model</td><td>complete</td><td>Successfully trained 10443</td></tr><tr><td>63662</td><td>15dc3c1ae0584f56bbf9155a7a20692f</td><td>1</td><td>2024-10-01T18:28:26.994+0000</td><td>false</td><td>63662_REVENUE_PMS_LGBM_model</td><td>complete</td><td>Successfully trained 63662</td></tr><tr><td>1406</td><td>586e0310bc0444e7b4722eda9957e3a5</td><td>1</td><td>2024-10-01T18:28:26.994+0000</td><td>false</td><td>1406_REVENUE_PMS_LGBM_model</td><td>complete</td><td>Successfully trained 1406</td></tr><tr><td>64942</td><td>ce468a942e32478a89654b6f7cb0cdc9</td><td>1</td><td>2024-10-01T18:28:26.994+0000</td><td>false</td><td>64942_REVENUE_PMS_LGBM_model</td><td>complete</td><td>Successfully trained 64942</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "71999",
         "3c5b82d9b6874242b8bb6cc0d148de9e",
         1,
         "2024-10-01T18:28:26.994+0000",
         false,
         "71999_REVENUE_PMS_LGBM_model",
         "complete",
         "Successfully trained 71999"
        ],
        [
         "10443",
         "eb0231c82a7743a08ac2b8afa658ad5b",
         1,
         "2024-10-01T18:28:26.994+0000",
         false,
         "10443_REVENUE_PMS_LGBM_model",
         "complete",
         "Successfully trained 10443"
        ],
        [
         "63662",
         "15dc3c1ae0584f56bbf9155a7a20692f",
         1,
         "2024-10-01T18:28:26.994+0000",
         false,
         "63662_REVENUE_PMS_LGBM_model",
         "complete",
         "Successfully trained 63662"
        ],
        [
         "1406",
         "586e0310bc0444e7b4722eda9957e3a5",
         1,
         "2024-10-01T18:28:26.994+0000",
         false,
         "1406_REVENUE_PMS_LGBM_model",
         "complete",
         "Successfully trained 1406"
        ],
        [
         "64942",
         "ce468a942e32478a89654b6f7cb0cdc9",
         1,
         "2024-10-01T18:28:26.994+0000",
         false,
         "64942_REVENUE_PMS_LGBM_model",
         "complete",
         "Successfully trained 64942"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "HotelID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "run_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "model_version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "pms_sync_off",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "model_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "output_df = output_df.toPandas()\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"Model training time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "341c1e34-68de-49d1-874d-878de427fe6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for index, row in output_df.iterrows():\n",
    "    if row.status == \"complete\":\n",
    "        logger.info(f\"{row.message}\")\n",
    "    else:\n",
    "        logger.error(\n",
    "            f\"Error encountered when training hotel {row.HotelID}: {row.message}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a482f7e-a5d3-4b6c-adfb-197898342b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "completed = output_df[output_df[\"status\"]==\"complete\"]\n",
    "\n",
    "outputs_list = []\n",
    "for n,g in completed.groupby([\"HotelID\",\"model_name\"]):\n",
    "    hotel_id = n[0]\n",
    "    model_name = n[1]\n",
    "    hotel_config = forecasting_config_provider.get_config(hotel_id)\n",
    "\n",
    "    mv = client.get_latest_versions(name=model_name)[0]\n",
    "    print(mv)\n",
    "    arts = client.list_artifacts(mv.run_id,path=f\"forecasting/{hotel_id}/models/{model_name}/artifacts\")\n",
    "    \n",
    "    outputs_list.append({\"hotel_id\":hotel_id,\n",
    "                         \"model_name\":model_name,\n",
    "                         \"creation_time\":datetime.datetime.fromtimestamp(mv.creation_timestamp/1e3),\n",
    "                         \"last_update\":datetime.datetime.fromtimestamp(mv.last_updated_timestamp/1e3),\n",
    "                         \"version\":mv.version,\n",
    "                         \"target\":TARGET_TYPE,\n",
    "                         \"exclude_pms\":WITHOUT_PMS,\n",
    "                         \"config_train_length\":hotel_config.training_length,\n",
    "                         \"config_infer_length\":hotel_config.inference_length,\n",
    "                         \"num_model_steps\":len(arts)-1})\n",
    "    \n",
    "    print(f\"Hotel: {hotel_id} target_type:{TARGET_TYPE} exclude_pms:{WITHOUT_PMS} : {len(arts)-1}\")\n",
    "\n",
    "completed_df = pd.DataFrame(outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb2c6d7e-faf6-4d8d-8553-5ddc4c7ad8b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "completed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65e80477-9dbe-480c-b6e6-ac4eb433065f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Model training completed.\")\n",
    "\n",
    "# elapsed_time = time.perf_counter() - start_time\n",
    "logger.info(f\"Time elapsed {elapsed_time}\")\n",
    "logger.info(f\"Time elapsed in minutes {elapsed_time/60}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "forecast_training_modified",
   "widgets": {
    "env_stage": {
     "currentValue": "dev",
     "nuid": "472aab7a-15fb-4978-88a6-47717a6d2cb7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": "Pipeline stage",
      "name": "env_stage",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "dev",
        "prod"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "dev",
      "label": "Pipeline stage",
      "name": "env_stage",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "dev",
        "prod"
       ]
      }
     }
    },
    "exclude_pms": {
     "currentValue": "False",
     "nuid": "31162b1e-a524-4814-af1b-c2c0958d9690",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "False",
      "label": "Exclude PMS",
      "name": "exclude_pms",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "True",
        "False"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "False",
      "label": "Exclude PMS",
      "name": "exclude_pms",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "True",
        "False"
       ]
      }
     }
    },
    "is_usd_currency": {
     "currentValue": "True",
     "nuid": "f3c47a96-fd90-40d9-a9e5-a0a30819bb53",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "True",
      "label": "Use USD currency",
      "name": "is_usd_currency",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "True",
        "False"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "True",
      "label": "Use USD currency",
      "name": "is_usd_currency",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "True",
        "False"
       ]
      }
     }
    },
    "lag_numbers": {
     "currentValue": "1,7,14,28",
     "nuid": "30b80cce-7dff-466d-b358-2456edf45c88",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "1,7,14,28",
      "label": "Lag Numbers",
      "name": "lag_numbers",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "1,7,14,28",
      "label": "Lag Numbers",
      "name": "lag_numbers",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "model_tags": {
     "currentValue": "",
     "nuid": "9f0bbb5f-7ca3-43f5-bce0-33f2d676cee9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Model Tags",
      "name": "model_tags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Model Tags",
      "name": "model_tags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "target_type": {
     "currentValue": "REVENUE",
     "nuid": "68009092-2839-4308-8c10-aa788c481f03",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "REVENUE",
      "label": "Target Type",
      "name": "target_type",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "REVENUE",
        "ROOMS"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "REVENUE",
      "label": "Target Type",
      "name": "target_type",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "REVENUE",
        "ROOMS"
       ]
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}