{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00a32b6b-1532-49fa-ae54-98676407f4af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"env_stage\", \"dev\", [\"dev\", \"prod\", \"qa\",\"dev_synxis_2_0\", \"prod_synxis_2_0\", \"qa_synxis_2_0\"], \"Pipeline stage\")\n",
    "dbutils.widgets.dropdown(\"exclude_pms\", \"False\", [\"True\", \"False\"], \"Exclude PMS\")\n",
    "dbutils.widgets.dropdown(\"target_type\", \"REVENUE\", [\"REVENUE\", \"ROOMS\"], \"Target Type\")\n",
    "dbutils.widgets.dropdown(\"is_usd_currency\", \"True\", [\"True\", \"False\"], \"Use USD currency\")\n",
    "dbutils.widgets.text(\"lag_numbers\",\"1,7,14,28\", \"Lag Numbers\")\n",
    "dbutils.widgets.text(\"model_tags\",\"\", \"Model Tags\")\n",
    "dbutils.widgets.text(\"thread_numbers\",\"1\", \"Number of Threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af2ea9c5-35d0-4e20-8279-9c332d4d31df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.2.2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47b521e3-cd66-4a2b-abb2-38f90bded5b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from sys import version_info\n",
    "import cloudpickle\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import logging\n",
    "import warnings\n",
    "from mlflow import MlflowException\n",
    "from mlflow.client import MlflowClient\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d844e9e-3bef-4eb0-a902-44c5af12cd0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45c52bb2-e39b-4474-b31b-9f147ffa330e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from phgml.models.xgboost_model import XGBMultiStepPredictor\n",
    "# from phgml.models.autogluon_model import AutoGluonModel, AGMlflowModel\n",
    "# from phgml.models.lightgbm_model import LightGBMModel, LGBMMlflowModel\n",
    "# from phgml.pipeline.training import train_wrapper\n",
    "from phgml.data.processing_distr_ca import (\n",
    "    filter_train_data,\n",
    "    filter_test_data,\n",
    "    remove_padded_cols,\n",
    ")\n",
    "from phgml.reporting.output_metrics import *\n",
    "from phgml.data.data_types import (\n",
    "    revenue_preprocessed_schema,\n",
    "    rooms_preprocessed_schema,\n",
    "    training_output_schema,\n",
    ")\n",
    "from phgml.reporting.logging import get_logging_path, get_logging_filename, get_dbx_logger\n",
    "from phgml.reporting.report_results import get_output_df, correct_prediction_list\n",
    "from phgml.data.config import EnvironmentConfig, ForecastingHotelConfigProvider \n",
    "from phgml.utilities.task_utilities import str_to_lst, str_to_bool, get_model_tags\n",
    "\n",
    "from phgml.models.model_wrapper import ModelWrapper\n",
    "from phgml.models.model_strategy import StrategyLGBM, StrategyAG\n",
    "from pyspark.sql.types import  TimestampType, StringType, StructField, StructType, DoubleType, LongType, BooleanType, FloatType, IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6a0ddc5-7bc9-4d24-a4e5-2ebb35200767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"ENV\"] = getArgument(\"env_stage\")\n",
    "params[\"CLUSTER_NAME\"] = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "params[\"REVENUE_COL\"] = \"_reservationRevenuePerRoomUSD\"\n",
    "params[\"ROOMS_COL\"] = \"rooms\"\n",
    "params[\"PIPELINE\"] = \"TRAINING\"\n",
    "params[\"WITHOUT_PMS\"] = str_to_bool(getArgument(\"exclude_pms\"))\n",
    "params[\"IS_USD_CURRENCY\"] = str_to_bool(getArgument(\"is_usd_currency\"))\n",
    "params[\"TARGET_TYPE\"] = getArgument(\"target_type\")\n",
    "params[\"MODEL_TAGS_DCT\"] = get_model_tags(getArgument(\"model_tags\"))\n",
    "print('model tags dict: ',params[\"MODEL_TAGS_DCT\"])\n",
    "\n",
    "# The start of the model data\n",
    "params[\"MODEL_START_DATE\"] = pd.to_datetime(\"2018-10-01\")\n",
    "params[\"COVID_START_DATE\"] = pd.to_datetime(\"2020-03-01\")\n",
    "params[\"COVID_END_DATE\"] = pd.to_datetime(\"2021-08-01\")\n",
    "\n",
    "params[\"CALC_UNCERTAINTY\"] = True\n",
    "params[\"LEAD_WINDOW\"] = 60\n",
    "params[\"PREDICTION_HORIZON\"] = 30\n",
    "params[\"ML_EXPERIMENT_ID\"] = 2169257822521486\n",
    "params[\"LAG_NUMBERS\"] = list(map(int,str_to_lst(getArgument('lag_numbers'))))\n",
    "params[\"SAVE_MODEL\"] = True\n",
    "params[\"SAVE_METRICS\"] = True\n",
    "params[\"THREAD_NUMBERS\"] = int(getArgument(\"thread_numbers\"))\n",
    "if getArgument('thread_numbers'):\n",
    "    params[\"THREAD_NUMBERS\"] = int(getArgument('thread_numbers'))\n",
    "\n",
    "params[\"LOG_ROOT\"] = '/dbfs/mnt/extractionlogs/synxis'\n",
    "if \"synxis_2_0\" in params[\"ENV\"]:\n",
    "    params[\"LOG_ROOT\"] = '/dbfs/mnt/extractionlogs/synxis_2_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0e2ec42-70ea-48a0-be33-7c5ef64ab1dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Disable adaptrive query optimization\n",
    "# Adaptive query optimization groups together smaller tasks into a larger tasks.\n",
    "# This may result in limited parallelism if the parallel inference tasks are deemed to be too small by the query optimizer\n",
    "# We are diableing AQE here to circumevent this limitation on parallelism\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "processing_timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3972705e-12cf-4910-9c29-156d1ab4e8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Config data relevant to this pipeline\n",
    "env_config = EnvironmentConfig(env=params[\"ENV\"], target=params[\"TARGET_TYPE\"], spark=spark, is_usd_currency=params[\"IS_USD_CURRENCY\"])\n",
    "forecasting_config_provider = ForecastingHotelConfigProvider(spark=spark,env=params[\"ENV\"])\n",
    "params[\"TARGET_COLUMN\"] = env_config.target_column\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "        \n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "processing_timestamp = datetime.datetime.now()\n",
    "\n",
    "logfile_path = get_logging_path(params[\"LOG_ROOT\"],processing_timestamp)\n",
    "if not os.path.exists(logfile_path):\n",
    "    os.makedirs(logfile_path)\n",
    "\n",
    "pms = \"PMS\"\n",
    "if params[\"WITHOUT_PMS\"]:\n",
    "    pms = \"NOPMS\"\n",
    "        \n",
    "log_file_name = get_logging_filename(\n",
    "    logfile_path,\n",
    "    params[\"PIPELINE\"],\n",
    "    params[\"TARGET_TYPE\"],\n",
    "    pms,\n",
    "    processing_timestamp)\n",
    "\n",
    "logger = logging.getLogger(f\"preprocess-{params['TARGET_TYPE']}-{pms}\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file_name)\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d87df22a-8bd1-4699-8ee2-e105c1bf2a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_column = env_config.target_column\n",
    "schema = training_output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95b7d906-4a02-41ba-94e3-ddb2bcf9c81e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Processing data for target type: {params['TARGET_TYPE']} : {params['TARGET_COLUMN']}\")\n",
    "logger.info(f\"Excluding PMS data? {params['WITHOUT_PMS']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea1d69f5-9d97-40b9-9303-4768d04c2284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Reading preprocessed data from table {env_config.preprocessed_data_table}\")\n",
    "logger.info(f\"Loading data from {env_config.preprocessed_data_table}\")\n",
    "df = spark.sql(f\"select * from {env_config.preprocessed_data_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86530798-7679-4352-92a0-499a1378058f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if df.count() <= 0:\n",
    "    logger.error(\"The loaded training dataset is empty.\")\n",
    "    logger.info(\"Terminting the pipeline execution\")\n",
    "    raise Exception(\"The loaded training dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "227ecadb-c3c7-4e1a-8646-647f31ef0333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # # For testing purposes\n",
    "# # # # d = d[d[\"HotelID\"]==\"71999\"]\n",
    "\n",
    "# # # CALC_UNCERTAINTY = True\n",
    "# # # SAVE_MODEL = True\n",
    "\n",
    "# fn = train_wrapper(\n",
    "#         target_type=params[\"TARGET_TYPE\"],\n",
    "#         ml_experiment_id=params[\"ML_EXPERIMENT_ID\"],\n",
    "#         exclude_pms=params[\"WITHOUT_PMS\"],\n",
    "#         calc_uncertainty=params[\"CALC_UNCERTAINTY\"],\n",
    "#         hotel_config_provider=forecasting_config_provider,\n",
    "#         processing_timestamp=processing_timestamp,\n",
    "#         save_models=False,\n",
    "#         save_metrics=False,\n",
    "#         lag_numbers=params[\"LAG_NUMBERS\"],\n",
    "#         model_tags=params[\"MODEL_TAGS_DCT\"],\n",
    "#         n_threads=params[\"THREAD_NUMBERS\"],\n",
    "#     )\n",
    "\n",
    "# df_pd = df.filter(df.HotelID=='27398').toPandas()\n",
    "# output = fn(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8c617d6-f161-4e01-8294-4df2aa997afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_wrapper(\n",
    "  model_type,\n",
    "  target_type,\n",
    "  exclude_pms,\n",
    "  calc_uncertainty,\n",
    "  prediction_horizon,\n",
    "  save_models,\n",
    "  save_metrics,\n",
    "  lag_numbers: List[int],\n",
    "  n_threads: int = 1,\n",
    "  meta_data={}\n",
    ") -> Callable:\n",
    "    def train_data_models(df):\n",
    "        static_cols_ = [\n",
    "          \"year\",\n",
    "          \"quarter_of_year\",\n",
    "          \"month_of_year\",\n",
    "          \"week_of_year\",\n",
    "          \"day_of_year\",\n",
    "          \"month_of_quarter\",\n",
    "          \"week_of_quarter\",\n",
    "          \"day_of_quarter\",\n",
    "          \"week_of_month\",\n",
    "          \"day_of_month\",\n",
    "          \"holiday\",\n",
    "          \"day_of_week_0\",\n",
    "          \"day_of_week_1\",\n",
    "          \"day_of_week_2\",\n",
    "          \"day_of_week_3\",\n",
    "          \"day_of_week_4\",\n",
    "          \"day_of_week_5\",\n",
    "          \"day_of_week_6\",\n",
    "        ]\n",
    "\n",
    "        logger = get_dbx_logger(\"PHGML\")\n",
    "\n",
    "        trainer = None\n",
    "        hotel_id = df[\"HotelID\"].iloc[0]\n",
    "\n",
    "        max_lead_window = 100\n",
    "\n",
    "        if target_type == \"REVENUE\":\n",
    "            col_prefix = \"RV\"\n",
    "        elif target_type == \"ROOMS\":\n",
    "            col_prefix = \"RM\"\n",
    "\n",
    "        df = remove_padded_cols(\n",
    "            df, max_lead_window, max_lead_window, col_prefix\n",
    "        )\n",
    "\n",
    "        test_partition_end = df[\"_StayDates\"].max()\n",
    "        test_partition_start = test_partition_end - pd.Timedelta(prediction_horizon,\"D\")\n",
    "        metadata_dict = meta_data\n",
    "\n",
    "        logger.debug(f\"{hotel_id}:Filter train data\")\n",
    "        dftrain = filter_train_data(df, test_partition_start)\n",
    "\n",
    "        logger.debug(f\"{hotel_id}:Filter test data\")\n",
    "        dftest = filter_test_data(\n",
    "            df,\n",
    "            test_partition_start=test_partition_start,\n",
    "            test_partition_end=test_partition_end,\n",
    "        )\n",
    "        dftest[\"day_ahead\"] = (dftest[\"_StayDates\"] - test_partition_start).dt.days\n",
    "        dftest = dftest[dftest.forecast_index == (dftest.day_ahead - 1)]\n",
    "\n",
    "        model_version = 1\n",
    "        model_stage = \"Staging\"\n",
    "        model_name = None\n",
    "\n",
    "        pms = \"PMS\"\n",
    "        if exclude_pms:\n",
    "            pms = \"NOPMS\"\n",
    "\n",
    "        # experiment_name=f\"{mlflow_user}{hotel_id}-{target_type}-{pms}-{prediction_horizon}days-new_hotel_eval\"\n",
    "\n",
    "        # if mlflow.get_experiment_by_name(experiment_name):\n",
    "        #     experiment_id=mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        # else:\n",
    "        #     experiment_id = mlflow.create_experiment(experiment_name) \n",
    "\n",
    "        experiment_id=2169257822521486\n",
    "\n",
    "        with mlflow.start_run(experiment_id=experiment_id,run_name=f\"RUN-{model_type}_{prediction_horizon}days-{hotel_id}-{target_type}-{pms}\") as run:\n",
    "          run_id = run.info.run_id\n",
    "          local_n_threads = n_threads\n",
    "          local_prediction_horizon = prediction_horizon\n",
    "          local_save_metrics = save_metrics\n",
    "\n",
    "          if model_type == \"AUTOGLUON\":\n",
    "            local_n_threads = 1\n",
    "\n",
    "            trainer = ModelWrapper(\n",
    "                model_strategy=StrategyAG,\n",
    "                is_auto_reg=True,\n",
    "                prediction_horizon=local_prediction_horizon,\n",
    "                mlflow_run_id=run_id,\n",
    "                hotel_id=hotel_id,\n",
    "                save_models=save_models,\n",
    "                target_type=target_type,\n",
    "                exclude_pms=exclude_pms,\n",
    "                model_name_prefix=f\"BACKUP_TEST_{local_prediction_horizon}DAY\",\n",
    "                meta_data=metadata_dict,\n",
    "                cd_axis_max_lags=99,\n",
    "                static_cols=static_cols_,\n",
    "                quantiles=[0.1, 0.5, 0.9],\n",
    "                n_threads=local_n_threads,\n",
    "            )\n",
    "          elif model_type == \"LIGHTGBM\":\n",
    "            trainer = ModelWrapper(\n",
    "                model_strategy=StrategyLGBM,\n",
    "                prediction_horizon=local_prediction_horizon,\n",
    "                mlflow_run_id=run_id,\n",
    "                hotel_id=hotel_id,\n",
    "                save_models=save_models,\n",
    "                target_type=target_type,\n",
    "                exclude_pms=exclude_pms,\n",
    "                model_name_prefix=f\"BACKUP_TEST_{local_prediction_horizon}DAY\",\n",
    "                meta_data=metadata_dict,\n",
    "                cd_axis_max_lags=99,\n",
    "                static_cols=static_cols_,\n",
    "                quantiles=[0.1, 0.5, 0.9],\n",
    "                n_threads=local_n_threads,\n",
    "            )\n",
    "\n",
    "          model_name = trainer.get_model_name()\n",
    "          output_df = pd.DataFrame()\n",
    "          try:\n",
    "            print(\"training\")\n",
    "            trainer.train(dftrain)\n",
    "\n",
    "            output_dct = trainer.predict(dftest)\n",
    "            y_pred , y_test , y_upper , y_lower = output_dct[0.5], output_dct['y_test'], output_dct[0.9], output_dct[0.1]\n",
    "\n",
    "            if local_save_metrics:\n",
    "                y_test_flat = [val for ar in y_test for val in ar]\n",
    "                y_pred_flat = [val for ar in y_pred for val in ar]\n",
    "                \n",
    "                SMAPE = mean_absolute_percentage_error(y_test_flat,y_pred_flat,symmetric=True)\n",
    "                MAE = mean_absolute_error(y_test_flat,y_pred_flat)\n",
    "\n",
    "                mlflow.log_metric(f\"SMAPE-{prediction_horizon}\", SMAPE)\n",
    "                mlflow.log_metric(f\"MAE-{prediction_horizon}\", MAE)\n",
    "                \n",
    "            dflst = []\n",
    "            for i,stay_date in enumerate(dftest[\"_StayDates\"].unique()):\n",
    "              \n",
    "              dfpart = pd.DataFrame(\n",
    "                {\n",
    "                  \"_StayDates\":[stay_date]*len(y_pred[i]),\n",
    "                  \"y_pred\":y_pred[i],\n",
    "                  \"y_true\":y_test[i]\n",
    "                })\n",
    "              dflst.append(dfpart)             \n",
    "              \n",
    "              output_df = pd.concat(dflst,axis=0)               \n",
    "              output_df[\"HotelID\"] = hotel_id \n",
    "              output_df[\"pms_sync_off\"] = exclude_pms\n",
    "              output_df[\"status\"] = \"complete\"\n",
    "              output_df[\"message\"] = f\"Successfully trained {hotel_id}\"                           \n",
    "              \n",
    "          except Exception as e:\n",
    "              raise e\n",
    "\n",
    "        output_df = output_df[[\"HotelID\",\"pms_sync_off\",\"status\",\"message\",\"_StayDates\",\"y_pred\",\"y_true\"]]\n",
    "        output_df.reset_index(drop=False, inplace=True)\n",
    "        return output_df\n",
    "\n",
    "    return train_data_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15551927-57f5-4854-aba0-9cc4954928c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training_output_schema = StructType(    \n",
    "    [\n",
    "        StructField(\"index\", StringType(), True),\n",
    "        StructField(\"HotelID\", StringType(), True),\n",
    "        StructField(\"pms_sync_off\",BooleanType(), True),\n",
    "        StructField(\"status\", StringType(), True),\n",
    "        StructField(\"message\", StringType(), True),\n",
    "        StructField(\"_StayDates\",DateType(),True),\n",
    "        StructField(\"y_pred\",FloatType(),True),\n",
    "        StructField(\"y_true\",FloatType(),True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41dc6507-2ba0-4ec6-a04b-3e5d58db919d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group the data by hotel id and execute the trainings in parallel\n",
    "logger.info(\"Starting parallel training\")\n",
    "\n",
    "output_df = df.groupby(\"HotelID\").applyInPandas(\n",
    "    train_wrapper(\n",
    "        model_type = \"LIGHTGBM\",\n",
    "        target_type=params[\"TARGET_TYPE\"],\n",
    "        # ml_experiment_id=params[\"ML_EXPERIMENT_ID\"],\n",
    "        exclude_pms=params[\"WITHOUT_PMS\"],\n",
    "        calc_uncertainty=params[\"CALC_UNCERTAINTY\"],\n",
    "        # hotel_config_provider=forecasting_config_provider,\n",
    "        # processing_timestamp=processing_timestamp,\n",
    "        prediction_horizon=28,\n",
    "        save_models=params[\"SAVE_MODEL\"],\n",
    "        save_metrics=params[\"SAVE_METRICS\"],\n",
    "        lag_numbers=params[\"LAG_NUMBERS\"],\n",
    "        # model_tags=params[\"MODEL_TAGS_DCT\"],\n",
    "        n_threads=params[\"THREAD_NUMBERS\"],\n",
    "        meta_data={}\n",
    "    ),\n",
    "    training_output_schema,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "456d621b-5d30-4cc9-84ad-f3936c855a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df = output_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1668cf78-e6c1-4941-864d-00a1626cf6fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for index, row in output_df.iterrows():\n",
    "    if row.status == \"complete\":\n",
    "        logger.info(f\"{row.message}\")\n",
    "    else:\n",
    "        logger.error(\n",
    "            f\"Error encountered when training hotel {row.HotelID}: {row.message}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea395c62-96d9-4254-80d1-f4cdada4d562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# client = MlflowClient()\n",
    "# completed = output_df[output_df[\"status\"]==\"complete\"]\n",
    "\n",
    "# outputs_list = []\n",
    "# for n,g in completed.groupby([\"HotelID\",\"model_name\"]):\n",
    "#     hotel_id = n[0]\n",
    "#     model_name = n[1]\n",
    "#     hotel_config = forecasting_config_provider.get_config(hotel_id)\n",
    "\n",
    "#     mv = client.get_latest_versions(name=model_name)[0]\n",
    "#     print(mv)\n",
    "#     arts = client.list_artifacts(mv.run_id,path=f\"forecasting/{hotel_id}/models/{model_name}/artifacts\")\n",
    "    \n",
    "#     outputs_list.append({\"hotel_id\":hotel_id,\n",
    "#                          \"model_name\":model_name,\n",
    "#                          \"creation_time\":datetime.datetime.fromtimestamp(mv.creation_timestamp/1e3),\n",
    "#                          \"last_update\":datetime.datetime.fromtimestamp(mv.last_updated_timestamp/1e3),\n",
    "#                          \"version\":mv.version,\n",
    "#                          \"target\":params[\"TARGET_TYPE\"],\n",
    "#                          \"exclude_pms\":params[\"WITHOUT_PMS\"],\n",
    "#                          \"config_train_length\":hotel_config.training_length,\n",
    "#                          \"config_infer_length\":hotel_config.inference_length,\n",
    "#                          \"num_model_steps\":len(arts)-1})\n",
    "    \n",
    "#     print(f\"Hotel: {hotel_id} target_type:{params['TARGET_TYPE']} exclude_pms:{params['WITHOUT_PMS']} : {len(arts)-1}\")\n",
    "\n",
    "# completed_df = pd.DataFrame(outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6e3936c-45b2-4f74-95ec-4530c7178dff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(completed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bd56ac6-9614-404a-9c2d-930462f921ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Model training completed.\")\n",
    "\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "logger.info(f\"Time elapsed {elapsed_time}\")\n",
    "logger.info(f\"Time elapsed in minutes {elapsed_time/60}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "forecast_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}