{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecaba58c-b428-46bd-86ed-ba3645878a69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"env_stage\", \"dev\", [\"dev\", \"prod\", \"qa\",\"dev_synxis_2_0\", \"prod_synxis_2_0\", \"qa_synxis_2_0\"], \"Pipeline stage\")\n",
    "dbutils.widgets.dropdown(\"source_catalog\", \"phg_data\", [\"dev_data\", \"qa_data\",\"phg_data\"], \"Source Catalog\")\n",
    "dbutils.widgets.dropdown(\"exclude_pms\", \"False\", [\"True\", \"False\"], \"Exclude PMS\")\n",
    "dbutils.widgets.dropdown(\"target_type\", \"REVENUE\", [\"REVENUE\", \"ROOMS\"], \"Target Type\")\n",
    "dbutils.widgets.dropdown(\"is_usd_currency\", \"True\", [\"True\", \"False\"], \"Use USD currency\")\n",
    "dbutils.widgets.text(\"selected_hotels\", \"\", \"Hotels\")\n",
    "dbutils.widgets.text(\"lag_numbers\",\"1,7,14,28\", \"Lag Numbers\")\n",
    "dbutils.widgets.text(\"model_start_date\", \"2018-10-01\", \"Model Start Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71570820-ccb9-45d9-ac66-7c1ba5416b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3f73b8c-d590-47ff-9487-dc124ae96e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    DateType,\n",
    "    IntegerType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    DoubleType,\n",
    "    LongType,\n",
    ")\n",
    "from sktime.transformations.series.date import DateTimeFeatures\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    mean_absolute_percentage_error,\n",
    "    MeanAbsolutePercentageError,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "import holidays\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from sys import version_info\n",
    "import cloudpickle\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "import pyspark.sql.functions as F\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c5105d9-5f00-4449-a4d2-2a40a59a1cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phgml.data.processing_distr_spark import (\n",
    "    filter_data,\n",
    "    preprocess_data,\n",
    "    get_lags,\n",
    "    compile_hotel_tables,    \n",
    ")\n",
    "from phgml.data.processing_distr_ca import filter_hotels\n",
    "from phgml.data.data_types import revenue_preprocessed_schema\n",
    "from phgml.data.config import EnvironmentConfig, ForecastingHotelConfigProvider \n",
    "from phgml.reporting.logging import get_logging_path, get_logging_filename, get_dbx_logger\n",
    "from phgml.utilities.task_utilities import str_to_lst, str_to_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5882003-fd9f-4fcc-b312-e5566772c814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read params\n",
    "params = {}\n",
    "params[\"ENV\"] = getArgument(\"env_stage\")\n",
    "params[\"SOURCE_CATALOG\"] = getArgument(\"source_catalog\")\n",
    "params[\"WITHOUT_PMS\"] = str_to_bool(getArgument(\"exclude_pms\"))\n",
    "params[\"IS_USD_CURRENCY\"] = str_to_bool(getArgument(\"is_usd_currency\"))\n",
    "params[\"TARGET_TYPE\"] = getArgument(\"target_type\")\n",
    "params[\"SELECTED_HOTELS\"] = str_to_lst(getArgument(\"selected_hotels\"))\n",
    "params[\"LAG_NUMBERS\"] = list(map(int,str_to_lst(getArgument('lag_numbers'))))\n",
    "params[\"REVENUE_COL\"] = \"_reservationRevenuePerRoomUSD\"\n",
    "params[\"ROOMS_COL\"] = \"_rooms\"\n",
    "params[\"PIPELINE\"] = \"PREPROCESS\"\n",
    "params[\"REPOPATH\"] = \"/Workspace/Repos/manik@surge.global/phg-data-mlsys/src\"\n",
    "params[\"MAXLEAD\"] = 100\n",
    "params[\"PREDICTION_HORIZON\"] = 28\n",
    "params[\"CA_AWARE\"] = True\n",
    "params[\"MODEL_START_DATE\"] = pd.to_datetime(getArgument(\"model_start_date\"))\n",
    "params[\"COVID_START_DATE\"] = pd.to_datetime(\"2020-03-01\")\n",
    "params[\"COVID_END_DATE\"] = pd.to_datetime(\"2021-08-01\")\n",
    "params[\"CALC_UNCERTAINTY\"] = True\n",
    "params[\"LOG_ROOT\"] = '/dbfs/mnt/extractionlogs/synxis'\n",
    "\n",
    "if \"synxis_2_0\" in params[\"ENV\"]:\n",
    "    params[\"LOG_ROOT\"] = '/dbfs/mnt/extractionlogs/synxis_2_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff038a72-1921-4a9a-ab42-ad115fa57aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env_config = EnvironmentConfig(env=params[\"ENV\"], target=params[\"TARGET_TYPE\"], spark=spark, is_usd_currency=params[\"IS_USD_CURRENCY\"])\n",
    "forecasting_config_provider = ForecastingHotelConfigProvider(spark=spark,env=params[\"ENV\"])\n",
    "params[\"TARGET_COLUMN\"] = env_config.target_column\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "        \n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "processing_timestamp = datetime.datetime.now()\n",
    "\n",
    "logfile_path = get_logging_path(params[\"LOG_ROOT\"],processing_timestamp)\n",
    "if not os.path.exists(logfile_path):\n",
    "    os.makedirs(logfile_path)\n",
    "\n",
    "pms = \"PMS\"\n",
    "if params['WITHOUT_PMS']:\n",
    "    pms = \"NOPMS\"\n",
    "        \n",
    "log_file_name = get_logging_filename(\n",
    "    logfile_path,\n",
    "    \"PREPROCESS\",\n",
    "    params['TARGET_TYPE'],\n",
    "    pms,\n",
    "    processing_timestamp)\n",
    "\n",
    "logger = logging.getLogger(f\"preprocess-{params['TARGET_TYPE']}-{pms}\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file_name)\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca2ab656-3865-441e-9f1b-92ce9985e0eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "        \n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "processing_timestamp = datetime.datetime.now()\n",
    "\n",
    "logfile_path = get_logging_path(params['LOG_ROOT'],processing_timestamp)\n",
    "if not os.path.exists(logfile_path):\n",
    "    os.makedirs(logfile_path)\n",
    "\n",
    "pms = \"PMS\"\n",
    "if params['WITHOUT_PMS']:\n",
    "    pms = \"NOPMS\"\n",
    "        \n",
    "log_file_name = get_logging_filename(\n",
    "    logfile_path,\n",
    "    \"PREPROCESS\",\n",
    "    params['TARGET_TYPE'],\n",
    "    pms,\n",
    "    processing_timestamp)\n",
    "\n",
    "logger = logging.getLogger(f\"preprocess-{params['TARGET_TYPE']}-{pms}\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file_name)\n",
    "file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23aa3260-96bc-4047-b417-a14fb55cc54e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Selecting hotels.\")\n",
    "hotel_details = spark.sql(\n",
    "    f\"select HotelID,HotelName,PMSStartDate,Country,State from {params['SOURCE_CATALOG']}.dim_hotels_data\"\n",
    ").toPandas()\n",
    "\n",
    "# Not considering state info other countries other than US and Canada for date features\n",
    "hotel_details.loc[~hotel_details.Country.isin(['US','CA']), \"State\"] = \"N/A\"\n",
    "hotel_details = hotel_details[~hotel_details.HotelID.isna()]\n",
    "\n",
    "correct_hotel_ids = filter_hotels(\n",
    "    hotel_details,\n",
    "    params[\"SELECTED_HOTELS\"],\n",
    "    params[\"WITHOUT_PMS\"],\n",
    "    forecasting_config_provider,\n",
    "    mode=\"TRAINING\"\n",
    ")\n",
    "\n",
    "print(f\"Corrected hotel ids: {correct_hotel_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22218fc6-a38a-44a6-99ce-d0653b06e78b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Loading data\")\n",
    "# Select transaction data along with the cancellation data from the raw dataset\n",
    "if \"synxis_2_0\" in params['ENV']:\n",
    "    \n",
    "    # changing the source tables to production because dev has less data maintained in its environment\n",
    "    env_config.source_data_table = f'{params[\"SOURCE_CATALOG\"]}.consumption_deaggrecords_v2'\n",
    "\n",
    "    dfsp_src = spark.sql(\n",
    "        f\"select * from {env_config.source_data_table}\"\n",
    "        )\n",
    "    \n",
    "    dfsp_src = dfsp_src.withColumn(\n",
    "        'cancellationDate',\n",
    "        F.when((F.col('status') == 'No-show')&(F.col('cancellationDate').isNull()), F.col('_StayDates')).otherwise(F.col('cancellationDate'))\n",
    "    )\n",
    "else:\n",
    "     # changing the source tables to production because dev has less data maintained in its environment\n",
    "    env_config.source_data_table = f'{params[\"SOURCE_CATALOG\"]}.consumption_deaggrecords'\n",
    "    env_config.transaction_data_table = f'{params[\"SOURCE_CATALOG\"]}.consumption_mrt'\n",
    "\n",
    "    dfsp_src = spark.sql(\n",
    "        f\"select a.TransactionID,a.HotelID,a._StayDates,a.confirmationDate,a.departureDate,a.channel,a.status,a.cancellationNumber,a._reservationRevenuePerRoomUSD,a._rooms,b.cancellationDate from {env_config.source_data_table} as a left join {env_config.transaction_data_table} as b on a.TransactionID=b.TransactionID\"\n",
    "        )\n",
    "\n",
    "dfsp_src = dfsp_src.filter(dfsp_src.HotelID.isin(correct_hotel_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a236b9ee-ad5d-4935-98b2-804e8b468c86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params['PARTITION_DATE'] = spark.sql(\n",
    "    f\"select max(confirmationDate) from {env_config.source_data_table}\"\n",
    ").collect()[0][0]\n",
    "\n",
    "print(f\"Using training data up to {params['PARTITION_DATE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b632dbbf-8e58-404e-8667-b44b857e574c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load booking statuses \n",
    "result = spark.sql(\"SELECT * FROM phg_data.bookings_status\")\n",
    "\n",
    "confirmed_status_list = [row['status'] for row in result.filter(result.scenario == 'confirmed').collect()]\n",
    "cancelled_status_list = [row['status'] for row in result.filter(result.scenario == 'cancelled').collect()]\n",
    "\n",
    "# Display the list\n",
    "print(f\"Confirmed Booking Status List: {confirmed_status_list}\")\n",
    "print(f\"Cancelled Booking Status List: {cancelled_status_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa33550c-17f2-40d1-94d4-f8cf7bc62fb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"HotelID\",\n",
    "    \"_StayDates\",\n",
    "    \"confirmationDate\",\n",
    "    \"channel\",\n",
    "    \"status\",\n",
    "    params[\"REVENUE_COL\"],\n",
    "    params[\"ROOMS_COL\"],\n",
    "]\n",
    "\n",
    "dfsp = dfsp_src.filter(\n",
    "        (F.col('status').isin(confirmed_status_list)) & (dfsp_src.cancellationDate.isNull())\n",
    "    ).select(columns)\n",
    "\n",
    "dfsp_ca = dfsp_src.filter(\n",
    "    ((F.col('status').isin(confirmed_status_list)) & (dfsp_src.cancellationDate.isNull())) |\n",
    "    ((F.col('status').isin(cancelled_status_list)) & (dfsp_src.cancellationDate.isNotNull()) & (F.col('cancellationDate') <= F.col('_StayDates')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b45edc5a-cf01-4f5e-a59b-f927dc64a04f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess_data(\n",
    "    dfsp,\n",
    "    params[\"WITHOUT_PMS\"],\n",
    "    params[\"REVENUE_COL\"],\n",
    "    params[\"ROOMS_COL\"],\n",
    "    params[\"MODEL_START_DATE\"],\n",
    "    cancel_aware=False\n",
    ")\n",
    "\n",
    "df_ca = preprocess_data(\n",
    "    dfsp_ca,\n",
    "    params[\"WITHOUT_PMS\"],\n",
    "    params[\"REVENUE_COL\"],\n",
    "    params[\"ROOMS_COL\"],\n",
    "    params[\"MODEL_START_DATE\"],\n",
    "    cancel_aware = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b62120df-aefd-47ab-9216-09e4fbbca8de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Loading data features\")\n",
    "model_start_date = params['MODEL_START_DATE']\n",
    "dates = spark.sql(f\"select * from phg_data.date_features where date >= '{model_start_date}'\")\n",
    "dates = dates.withColumn('date', F.to_date('date'))\n",
    "dates = dates.withColumnRenamed(\"date\",\"_StayDates\")\n",
    "dates = dates.join(\n",
    "    spark.createDataFrame(hotel_details[[\"HotelID\",\"Country\",\"State\"]]), \n",
    "    on=['Country','State'],\n",
    "     how=\"inner\")\n",
    "\n",
    "logger.info(\"Calculate lags\")\n",
    "df_lags = get_lags(\n",
    "    df,\n",
    "    lag_numbers=params[\"LAG_NUMBERS\"], \n",
    "    target_col=params[\"TARGET_COLUMN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "962e3fb1-0a8e-4622-9d6b-2caa37830f1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Stay dates filtering upto : {params['PARTITION_DATE']}\")\n",
    "df = filter_data(\n",
    "    df=df, \n",
    "    partition_date=params[\"PARTITION_DATE\"], \n",
    "    revenue_col=params[\"REVENUE_COL\"], \n",
    "    rooms_col=params[\"ROOMS_COL\"], \n",
    "    cancel_aware=False\n",
    ")\n",
    "\n",
    "df_ca = filter_data(\n",
    "    df=df_ca,\n",
    "    partition_date=params[\"PARTITION_DATE\"],\n",
    "    revenue_col=params[\"REVENUE_COL\"],\n",
    "    rooms_col=params[\"ROOMS_COL\"],\n",
    "    cancel_aware=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4409d6bc-736b-4940-9c63-9c3ce86d3140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Executing pipeline stage: {params['ENV']}\")\n",
    "logger.info(f\"Processing data for target type: {params['TARGET_TYPE']} : {params['TARGET_COLUMN']}\")\n",
    "logger.info(f\"Excluding PMS data? {params['WITHOUT_PMS']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccc5b3f5-6f84-4b49-b0f4-d96e741fb92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Compiling train data set\")\n",
    "output_df_targets = compile_hotel_tables(\n",
    "    df=df,\n",
    "    target_type=params[\"TARGET_TYPE\"],\n",
    "    target_column=params[\"TARGET_COLUMN\"],\n",
    "    prediction_horizon=params[\"PREDICTION_HORIZON\"],\n",
    "    lead_window=params[\"PREDICTION_HORIZON\"],\n",
    "    selected_hotels=correct_hotel_ids,\n",
    "    spark=spark,\n",
    "    suffix=\"_tgt\"\n",
    ")\n",
    "\n",
    "output_df_ca = compile_hotel_tables(\n",
    "    df=df_ca, \n",
    "    target_type=params[\"TARGET_TYPE\"],\n",
    "    target_column=params[\"TARGET_COLUMN\"],\n",
    "    prediction_horizon=params[\"PREDICTION_HORIZON\"],\n",
    "    lead_window=params[\"MAXLEAD\"],\n",
    "    selected_hotels=correct_hotel_ids,\n",
    "    spark=spark,\n",
    "    dates=dates,\n",
    "    df_lags=df_lags,\n",
    "    cancel_aware=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91dbe742-ea86-4e36-9985-21d74bfde193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df = output_df_targets.join(output_df_ca, on=['HotelID','_StayDates'], how='inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41fccb55-bf85-4fca-8d56-d39000b761eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params[\"ENV_NAME\"] = 'phg' if params[\"ENV\"]=='prod' else params[\"ENV\"]\n",
    "params[\"DATE_REMOVAL_TB_NAME\"] = f\"{params['ENV_NAME']}_data.config_date_range_removal\"\n",
    "\n",
    "date_removal_df_retrieved=None\n",
    "try:\n",
    "    date_removal_df_retrieved = spark.sql(f\"select * from {params['DATE_REMOVAL_TB_NAME']}\")\n",
    "    date_removal_df_retrieved = date_removal_df_retrieved.filter(date_removal_df_retrieved.pipeline=='main_training_pipeline')\n",
    "    date_removal_df_retrieved = date_removal_df_retrieved.filter(date_removal_df_retrieved.HotelID.isin(params[\"SELECTED_HOTELS\"]))\n",
    "    date_removal_df_retrieved = date_removal_df_retrieved.toPandas()\n",
    "    date_removal_df_retrieved = date_removal_df_retrieved.groupby('HotelID').apply(lambda x: x[x.timestamp==x.timestamp.max()]).reset_index(drop=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if type(date_removal_df_retrieved)!=type(None):\n",
    "    filtered_data_sp = None\n",
    "    for hid in params[\"SELECTED_HOTELS\"]:\n",
    "        print(hid)\n",
    "        train_data_cpy_sp = output_df.filter(output_df.HotelID==hid)\n",
    "        st_dates_lst = date_removal_df_retrieved[date_removal_df_retrieved.HotelID==hid].date_range_start.values\n",
    "        end_dates_lst = date_removal_df_retrieved[date_removal_df_retrieved.HotelID==hid].date_range_end.values\n",
    "        if len(st_dates_lst)>0:\n",
    "            for st_date, end_date in zip(st_dates_lst,end_dates_lst):\n",
    "                print(st_date,end_date)\n",
    "                st_date = pd.to_datetime(st_date)\n",
    "                end_date = pd.to_datetime(end_date)\n",
    "                train_data_cpy_sp= train_data_cpy_sp.filter(~((train_data_cpy_sp._StayDates>=st_date)&(train_data_cpy_sp._StayDates<=end_date)))\n",
    "        else:\n",
    "            print(\"No removal date ranges present\")\n",
    "        \n",
    "        if type(filtered_data_sp)!=type(None):\n",
    "            filtered_data_sp = filtered_data_sp.union(train_data_cpy_sp)\n",
    "        else:\n",
    "            filtered_data_sp=train_data_cpy_sp\n",
    "    \n",
    "    output_df =filtered_data_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049b080a-9eba-445e-bb22-673bb4d4ad9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_format = \"delta\"\n",
    "print(f\"Writing preprocessed data to table {env_config.preprocessed_data_table}\")\n",
    "logger.info(f\"Writing preprocessed data to table {env_config.preprocessed_data_table}\")\n",
    "(\n",
    "    output_df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"HotelID\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(env_config.preprocessed_data_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a444a6-50a9-4f69-9834-9f92a9e84c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "elapsed_time = time.perf_counter() - start_time\n",
    "logger.info(f\"Time elapsed {elapsed_time}\")\n",
    "logger.info(f\"Time elapsed in minutes {elapsed_time/60}\")\n",
    "print(f\"Time elapsed in minutes {elapsed_time/60}\")\n",
    "logger.info(\"Preprocessing completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "forecast_data_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}